
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>mdp_playground.envs.rl_toy_env &#8212; MDP Playground 0.0.1 documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      
      <h1 class="site-logo" id="site-title">MDP Playground 0.0.1 documentation</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../_autosummary/mdp_playground.html">
   mdp_playground
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../_autosummary/mdp_playground.analysis.html">
     mdp_playground.analysis
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.analysis.analysis.html">
       mdp_playground.analysis.analysis
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.analysis.analysis.MDPP_Analysis.html">
         mdp_playground.analysis.analysis.MDPP_Analysis
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.analysis.radar_chart.html">
       mdp_playground.analysis.radar_chart
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
      <label for="toctree-checkbox-4">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.analysis.radar_chart.radar_factory.html">
         mdp_playground.analysis.radar_chart.radar_factory
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../_autosummary/mdp_playground.config_processor.html">
     mdp_playground.config_processor
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.html">
     mdp_playground.envs
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.gym_env_wrapper.html">
       mdp_playground.envs.gym_env_wrapper
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.gym_env_wrapper.GymEnvWrapper.html">
         mdp_playground.envs.gym_env_wrapper.GymEnvWrapper
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.mujoco_env_wrapper.html">
       mdp_playground.envs.mujoco_env_wrapper
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.mujoco_env_wrapper.get_mujoco_wrapper.html">
         mdp_playground.envs.mujoco_env_wrapper.get_mujoco_wrapper
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.html">
       mdp_playground.envs.rl_toy_env
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.dist_of_pt_from_line.html">
         mdp_playground.envs.rl_toy_env.dist_of_pt_from_line
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.list_to_float_np_array.html">
         mdp_playground.envs.rl_toy_env.list_to_float_np_array
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html">
         mdp_playground.envs.rl_toy_env.RLToyEnv
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../_autosummary/mdp_playground.scripts.html">
     mdp_playground.scripts
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.scripts.run_experiments.html">
       mdp_playground.scripts.run_experiments
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.scripts.run_experiments.cli.html">
         mdp_playground.scripts.run_experiments.cli
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.scripts.run_experiments.main.html">
         mdp_playground.scripts.run_experiments.main
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.html">
     mdp_playground.spaces
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.box_extended.html">
       mdp_playground.spaces.box_extended
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
      <label for="toctree-checkbox-12">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.box_extended.BoxExtended.html">
         mdp_playground.spaces.box_extended.BoxExtended
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.discrete_extended.html">
       mdp_playground.spaces.discrete_extended
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
      <label for="toctree-checkbox-13">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.discrete_extended.DiscreteExtended.html">
         mdp_playground.spaces.discrete_extended.DiscreteExtended
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.image_continuous.html">
       mdp_playground.spaces.image_continuous
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
      <label for="toctree-checkbox-14">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.image_continuous.ImageContinuous.html">
         mdp_playground.spaces.image_continuous.ImageContinuous
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.image_multi_discrete.html">
       mdp_playground.spaces.image_multi_discrete
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.image_multi_discrete.ImageMultiDiscrete.html">
         mdp_playground.spaces.image_multi_discrete.ImageMultiDiscrete
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.multi_discrete_extended.html">
       mdp_playground.spaces.multi_discrete_extended
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.multi_discrete_extended.MultiDiscreteExtended.html">
         mdp_playground.spaces.multi_discrete_extended.MultiDiscreteExtended
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.test_image_continuous.html">
       mdp_playground.spaces.test_image_continuous
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.test_image_continuous.TestImageContinuous.html">
         mdp_playground.spaces.test_image_continuous.TestImageContinuous
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.test_image_multi_discrete.html">
       mdp_playground.spaces.test_image_multi_discrete
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.test_image_multi_discrete.TestImageMultiDiscrete.html">
         mdp_playground.spaces.test_image_multi_discrete.TestImageMultiDiscrete
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.tuple_extended.html">
       mdp_playground.spaces.tuple_extended
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
      <label for="toctree-checkbox-19">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="../../../_autosummary/mdp_playground.spaces.tuple_extended.TupleExtended.html">
         mdp_playground.spaces.tuple_extended.TupleExtended
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <h1>Source code for mdp_playground.envs.rl_toy_env</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">scipy.spatial</span> <span class="kn">import</span> <span class="n">distance</span>
<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">mdp_playground.spaces</span> <span class="kn">import</span> <span class="n">BoxExtended</span><span class="p">,</span> <span class="n">DiscreteExtended</span><span class="p">,</span> <span class="n">TupleExtended</span><span class="p">,</span>\
        <span class="n">ImageMultiDiscrete</span><span class="p">,</span> <span class="n">ImageContinuous</span>


<div class="viewcode-block" id="RLToyEnv"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv">[docs]</a><span class="k">class</span> <span class="nc">RLToyEnv</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The base toy environment in MDP Playground. It is parameterised by a config dict and can be instantiated to be an MDP with any of the possible dimensions from the accompanying research paper. The class extends OpenAI Gym&#39;s environment gym.Env.</span>

<span class="sd">    The accompanying paper is available at: https://arxiv.org/abs/1909.07750.</span>

<span class="sd">    Instead of implementing a new class for every type of MDP, the intent is to capture as many common dimensions across different types of environments as possible and to be able to control the difficulty of an environment by allowing fine-grained control over each of these dimensions. The focus is to be as flexible as possible.</span>

<span class="sd">    The configuration for the environment is passed as a dict at initialisation and contains all the information needed to determine the dynamics of the MDP that the instantiated environment will emulate. We recommend looking at the examples in example.py to begin using the environment since the dimensions and config options are mostly self-explanatory. If you want to specify custom MDPs, please see the use_custom_mdp config option below. For more details, we list here the dimensions and config options (their names here correspond to the keys to be passed in the config dict):</span>
<span class="sd">        state_space_type : str</span>
<span class="sd">            Specifies what the environment type is. Options are &quot;continuous&quot;, &quot;discrete&quot; and &quot;grid&quot;. The &quot;grid&quot; environment is, basically, a discretised version of the continuous environment.</span>
<span class="sd">        delay : int &gt;= 0</span>
<span class="sd">            Delays each reward by this number of timesteps.</span>
<span class="sd">        sequence_length : int &gt;= 1</span>
<span class="sd">            Intrinsic sequence length of the reward function of an environment. For discrete environments, randomly selected sequences of this length are set to be rewardable at initialisation if use_custom_mdp = false and generate_random_mdp = true.</span>
<span class="sd">        transition_noise : float in range [0, 1] or Python function(rng)</span>
<span class="sd">            For discrete environments, it is a float that specifies the fraction of times the environment transitions to a noisy next state at each timestep, independently and uniformly at random.</span>
<span class="sd">            For continuous environments, if it&#39;s a float, it&#39;s used as the standard deviation of an i.i.d. normal distribution of noise. If it is a Python function with one argument, it is added to next state. The argument is the Random Number Generator (RNG) of the environment which is an np.random.RandomState object. This RNG should be used to perform calls to the desired random function to be used as noise to ensure reproducibility.</span>
<span class="sd">        reward_noise : float or Python function(rng)</span>
<span class="sd">            If it&#39;s a float, it&#39;s used as the standard deviation of an i.i.d. normal distribution of noise.</span>
<span class="sd">            If it&#39;s a Python function with one argument, it is added to the reward given at every time step. The argument is the Random Number Generator (RNG) of the environment which is an np.random.RandomState object. This RNG should be used to perform calls to the desired random function to be used as noise to ensure reproducibility.</span>
<span class="sd">        reward_density : float in range [0, 1]</span>
<span class="sd">            The fraction of possible sequences of a given length that will be selected to be rewardable at initialisation time.</span>
<span class="sd">        reward_scale : float</span>
<span class="sd">            Multiplies the rewards by this value at every time step.</span>
<span class="sd">        reward_shift : float</span>
<span class="sd">            This value is added to the reward at every time step.</span>
<span class="sd">        diameter : int &gt; 0</span>
<span class="sd">            For discrete environments, if diameter = d, the set of states is set to be a d-partite graph (and NOT a complete d-partite graph), where, if we order the d sets as 1, 2, .., d, states from set 1 will have actions leading to states in set 2 and so on, with the final set d having actions leading to states in set 1. Number of actions for each state will, thus, be = (number of states) / (d).</span>
<span class="sd">        terminal_state_density : float in range [0, 1]</span>
<span class="sd">            For discrete environments, the fraction of states that are terminal; the terminal states are fixed to the &quot;last&quot; states when we consider them to be ordered by their numerical value. This is w.l.o.g. because discrete states are categorical. For continuous environments, please see terminal_states and term_state_edge for how to control terminal states.</span>
<span class="sd">        term_state_reward : float</span>
<span class="sd">            Adds this to the reward if a terminal state was reached at the current time step.</span>
<span class="sd">        image_representations : boolean</span>
<span class="sd">            Boolean to associate an image as the external observation with every discrete categorical state.</span>
<span class="sd">            For discrete envs, this is handled by an mdp_playground.spaces.ImageMultiDiscrete object. It associates the image of an n + 3 sided polygon for a categorical state n. More details can be found in the documentation for the ImageMultiDiscrete class.</span>
<span class="sd">            For continuous and grid envs, this is handled by an mdp_playground.spaces.ImageContinuous object. More details can be found in the documentation for the ImageContinuous class.</span>
<span class="sd">        irrelevant_features : boolean</span>
<span class="sd">            If True, an additional irrelevant sub-space (irrelevant to achieving rewards) is present as part of the observation space. This sub-space has its own transition dynamics independent of the dynamics of the relevant sub-space.</span>
<span class="sd">            For discrete environments, additionally, state_space_size must be specified as a list.</span>
<span class="sd">            For continuous environments, the option relevant_indices must be specified. This option specifies the dimensions relevant to achieving rewards.</span>
<span class="sd">            For grid environments, nothing additional needs to be done as relevant grid shape is also used as the irrelevant grid shape.</span>
<span class="sd">        use_custom_mdp : boolean</span>
<span class="sd">            If true, users specify their own transition and reward functions using the config options transition_function and reward_function (see below). Optionally, they can also use init_state_dist and terminal_states for discrete spaces (see below).</span>
<span class="sd">        transition_function : Python function(state, action) or a 2-D numpy.ndarray</span>
<span class="sd">            A Python function emulating P(s, a). For discrete envs it&#39;s also possible to specify an |S|x|A| transition matrix.</span>
<span class="sd">        reward_function : Python function(state_sequence, action_sequence) or a 2-D numpy.ndarray</span>
<span class="sd">            A Python function emulating R(state_sequence, action_sequence). The state_sequence is recorded by the environment and transition_function is called before reward_function, so the &quot;current&quot; state (when step() was called) and next state are the last 2 states in the sequence.</span>
<span class="sd">            For discrete environments, it&#39;s also possible to specify an |S|x|A| transition matrix where reward is assumed to be a function over the &quot;current&quot; state and action.</span>
<span class="sd">            If use_custom_mdp = false and the environment is continuous, this is a string that chooses one of the following predefined reward functions: move_along_a_line or move_to_a_point.</span>
<span class="sd">            If use_custom_mdp = false and the environment is grid, this is a string that chooses one of the following predefined reward functions: move_to_a_point. Support for sequences is planned.</span>

<span class="sd">            Also see make_denser documentation.</span>


<span class="sd">        Specific to discrete environments:</span>
<span class="sd">            state_space_size : int &gt; 0 or list of length 2</span>
<span class="sd">                A number specifying size of the state space for normal discrete environments and a list of len = 2 when irrelevant_features is True (The list contains sizes of relevant and irrelevant sub-spaces where the 1st sub-space is assumed relevant and the 2nd sub-space is assumed irrelevant).</span>
<span class="sd">                NOTE: When automatically generating MDPs, do not specify this value as its value depends on the action_space_size and the diameter as state_space_size = action_space_size * diameter.</span>
<span class="sd">            action_space_size : int &gt; 0</span>
<span class="sd">                Similar description as state_space_size. When automatically generating MDPs, however, its value determines the state_space_size.</span>
<span class="sd">            reward_dist : list with 2 floats or a Python function(env_rng, reward_sequence_dict)</span>
<span class="sd">                If it&#39;s a list with 2 floats, then these 2 values are interpreted as a closed interval and taken as the end points of a categorical distribution which points equally spaced along the interval.</span>
<span class="sd">                If it&#39;s a Python function, it samples rewards for the rewardable_sequences dict of the environment. The rewardable_sequences dict of the environment holds the rewardable_sequences with the key as a tuple holding the sequence and value as the reward handed out. The 1st argument for the reward_dist function is the Random Number Generator (RNG) of the environment which is an np.random.RandomState object. This RNG should be used to perform calls to the desired random function to be used to sample rewards to ensure reproducibility. The 2nd argument is the rewardable_sequences dict of the environment. This is available because one may need access to the already created reward sequences in the reward_dist function.</span>
<span class="sd">            init_state_dist : 1-D numpy.ndarray</span>
<span class="sd">                Specifies an array of initialisation probabilities for the discrete state space.</span>
<span class="sd">            terminal_states : Python function(state) or 1-D numpy.ndarray</span>
<span class="sd">                A Python function with the state as argument that returns whether the state is terminal. If this is specified as an array, the array lists the discrete states that are terminal.</span>

<span class="sd">            Specific to image_representations for discrete envs:</span>
<span class="sd">                image_transforms : str</span>
<span class="sd">                    String containing the transforms that must be applied to the image representations. As long as one of the following words is present in the string - shift, scale, rotate, flip - the corresponding transform will be applied at random to the polygon in the image representation whenever an observation is generated. Care is either explicitly taken that the polygon remains inside the image region or a warning is generated.</span>
<span class="sd">                sh_quant : int</span>
<span class="sd">                    An int to quantise the shift transforms.</span>
<span class="sd">                scale_range : (float, float)</span>
<span class="sd">                    A tuple of real numbers to specify (min_scaling, max_scaling).</span>
<span class="sd">                ro_quant : int</span>
<span class="sd">                    An int to quantise the rotation transforms.</span>

<span class="sd">        Specific to continuous environments:</span>
<span class="sd">            state_space_dim : int</span>
<span class="sd">                A number specifying state space dimensionality. A Gym Box space of this dimensionality will be instantiated.</span>
<span class="sd">            action_space_dim : int</span>
<span class="sd">                Same description as state_space_dim. This is currently set equal to the state_space_dim and doesn&#39;t need to specified.</span>
<span class="sd">            relevant_indices : list</span>
<span class="sd">                A list that provides the dimensions relevant to achieving rewards for continuous environments. The dynamics for these dimensions are independent of the dynamics for the remaining (irrelevant) dimensions.</span>
<span class="sd">            state_space_max : float</span>
<span class="sd">                Max absolute value that a dimension of the space can take. A Gym Box will be instantiated with range [-state_space_max, state_space_max]. Sampling will be done as for Gym Box spaces.</span>
<span class="sd">            action_space_max : float</span>
<span class="sd">                Similar description as for state_space_max.</span>
<span class="sd">            terminal_states : numpy.ndarray</span>
<span class="sd">                The centres of hypercube sub-spaces which are terminal.</span>
<span class="sd">            term_state_edge : float</span>
<span class="sd">                The edge of the hypercube sub-spaces which are terminal.</span>
<span class="sd">            transition_dynamics_order : int</span>
<span class="sd">                An order of n implies that the n-th state derivative is set equal to the action/inertia.</span>
<span class="sd">            inertia : float or numpy.ndarray</span>
<span class="sd">                inertia of the rigid body or point object that is being simulated. If numpy.ndarray, it specifies independent inertiae for the dimensions and the shape should be (state_space_dim,).</span>
<span class="sd">            time_unit : float</span>
<span class="sd">                time duration over which the action is applied to the system.</span>
<span class="sd">            target_point : numpy.ndarray</span>
<span class="sd">                The target point in case move_to_a_point is the reward_function. If make_denser is false, target_radius determines distance from the target point at which the sparse reward is handed out.</span>
<span class="sd">            action_loss_weight : float</span>
<span class="sd">                A coefficient to multiply the norm of the action and subtract it from the reward to penalise the action magnitude.</span>

<span class="sd">        Specific to grid environments:</span>
<span class="sd">            grid_shape : tuple</span>
<span class="sd">                Shape of the grid environment. If irrelevant_features is True, this is replicated to add a grid which is irrelevant to the reward.</span>
<span class="sd">            target_point : numpy.ndarray</span>
<span class="sd">                The target point in case move_to_a_point is the reward_function. If make_denser is false, reward is only handed out when the target point is reached.</span>
<span class="sd">            terminal_states : Python function(state) or 1-D numpy.ndarray</span>
<span class="sd">                Same description as for terminal_states under discrete envs</span>

<span class="sd">    Other important config:</span>
<span class="sd">        Specific to discrete environments:</span>
<span class="sd">            repeats_in_sequences : boolean</span>
<span class="sd">                If true, allows rewardable sequences to have repeating states in them.</span>
<span class="sd">            maximally_connected : boolean</span>
<span class="sd">                If true, sets the transition function such that every state in independent set i can transition to every state in independent set i + 1. If false, then sets the transition function such that a state in independent set i may have any state in independent set i + 1 as the next state for a transition.</span>
<span class="sd">            reward_every_n_steps : boolean</span>
<span class="sd">                Hand out rewards only at multiples of sequence_length steps. This makes the probability that an agent is executing overlapping rewarding sequences 0. This makes it simpler to evaluate HRL algorithms and whether they can &quot;discretise&quot; time correctly. Noise is added at every step, regardless of this setting. Currently, not implemented for either the make_denser = true case or for continuous and grid environments.</span>
<span class="sd">            generate_random_mdp : boolean</span>
<span class="sd">                If true, automatically generate MDPs when use_custom_mdp = false. Currently, this option doesn&#39;t need to be specified because random MDPs are always generated when use_custom_mdp = false.</span>

<span class="sd">        Specific to continuous environments:</span>
<span class="sd">            none as of now</span>

<span class="sd">        For all, continuous, discrete and grid environments:</span>
<span class="sd">        make_denser : boolean</span>
<span class="sd">            If true, makes the reward denser in environments.</span>
<span class="sd">            For discrete environments, hands out a partial reward for completing partial sequences.</span>
<span class="sd">            For continuous environments, for reward function move_to_a_point, the base reward handed out is equal to the distance moved towards the target point in the current timestep.</span>
<span class="sd">            For grid envs, the base reward handed out is equal to the Manhattan distance moved towards the target point in the current timestep.</span>
<span class="sd">        seed : int or dict</span>
<span class="sd">            Recommended to be passed as an int which generates seeds to be used for the various components of the environment. It is, however, possible to control individual seeds by passing it as a dict. Please see the default initialisation for seeds below to see how to do that.</span>
<span class="sd">        log_filename : str</span>
<span class="sd">            The name of the log file to which logs are written.</span>
<span class="sd">        log_level : logging.LOG_LEVEL option</span>
<span class="sd">            Python log level for logging</span>

<span class="sd">    Below, we list the important attributes and methods for this class.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    config : dict</span>
<span class="sd">        the config contains all the details required to generate an environment</span>
<span class="sd">    seed : int or dict</span>
<span class="sd">        recommended to set to an int, which would set seeds for the env, relevant and irrelevant and externally visible observation and action spaces automatically. If fine-grained control over the seeds is necessary, a dict, with key values as in the source code further below, can be passed.</span>
<span class="sd">    observation_space : Gym.Space</span>
<span class="sd">        The externally visible observation space for the enviroment.</span>
<span class="sd">    action_space : Gym.Space</span>
<span class="sd">        The externally visible action space for the enviroment.</span>
<span class="sd">    rewardable_sequences : dict</span>
<span class="sd">        holds the rewardable sequences. The keys are tuples of rewardable sequences and values are the rewards handed out. When make_denser is True for discrete environments, this dict also holds the rewardable partial sequences.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    init_terminal_states()</span>
<span class="sd">        Initialises terminal states, T</span>
<span class="sd">    init_init_state_dist()</span>
<span class="sd">        Initialises initial state distribution, rho_0</span>
<span class="sd">    init_transition_function()</span>
<span class="sd">        Initialises transition function, P</span>
<span class="sd">    init_reward_function()</span>
<span class="sd">        Initialises reward function, R</span>
<span class="sd">    transition_function(state, action)</span>
<span class="sd">        the transition function of the MDP, P</span>
<span class="sd">    P(state, action)</span>
<span class="sd">        defined as a lambda function in the call to init_transition_function() and is equivalent to calling transition_function()</span>
<span class="sd">    reward_function(state, action)</span>
<span class="sd">        the reward function of the MDP, R</span>
<span class="sd">    R(state, action)</span>
<span class="sd">        defined as a lambda function in the call to init_reward_function() and is equivalent to calling reward_function()</span>
<span class="sd">    get_augmented_state()</span>
<span class="sd">        gets underlying Markovian state of the MDP</span>
<span class="sd">    reset()</span>
<span class="sd">        Resets environment state</span>
<span class="sd">    seed()</span>
<span class="sd">        Sets the seed for the numpy RNG used by the environment (state and action spaces have their own seeds as well)</span>
<span class="sd">    step(action, imaginary_rollout=False)</span>
<span class="sd">        Performs 1 transition of the MDP</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RLToyEnv.__init__"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">config</span><span class="p">):</span> <span class="c1"># = None):</span>
        <span class="sd">&quot;&quot;&quot;Initialises the MDP to be emulated using the settings provided in config.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        config : dict</span>
<span class="sd">            the member variable config is initialised to this value after inserting defaults</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Passed config:&quot;</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set default settings for config to be able to use class without any config being passed</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">config</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1">#is None:</span>
            <span class="c1"># config = {}</span>

            <span class="c1"># Discrete spaces configs:</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;discrete&quot;</span> <span class="c1"># TODO if states are assumed categorical in discrete setting, need to have an embedding for their OHE when using NNs; do the encoding on the training end!</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span> <span class="c1"># To be given as an integer for simple Discrete environment like Gym&#39;s. To be given as a list of integers for a MultiDiscrete environment like Gym&#39;s #TODO Rename state_space_size and action_space_size to be relevant_... wherever irrelevant dimensions are not used.</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_space_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>

            <span class="c1"># Continuous spaces configs:</span>
            <span class="c1"># config[&quot;state_space_type&quot;] = &quot;continuous&quot;</span>
            <span class="c1"># config[&quot;state_space_dim&quot;] = 2</span>
            <span class="c1"># config[&quot;action_space_dim&quot;] = 2</span>
            <span class="c1"># config[&quot;transition_dynamics_order&quot;] = 1</span>
            <span class="c1"># config[&quot;inertia&quot;] = 1 # 1 unit, e.g. kg for mass, or kg * m^2 for moment of inertia.</span>
            <span class="c1"># config[&quot;state_space_max&quot;] = 5 # Will be a Box in the range [-max, max]</span>
            <span class="c1"># config[&quot;action_space_max&quot;] = 5 # Will be a Box in the range [-max, max]</span>
            <span class="c1"># config[&quot;time_unit&quot;] = 0.01 # Discretization of time domain</span>
            <span class="c1"># config[&quot;terminal_states&quot;] = [[0.0, 1.0], [1.0, 0.0]]</span>
            <span class="c1"># config[&quot;term_state_edge&quot;] =  1.0 # Terminal states will be in a hypercube centred around the terminal states given above with the edge of the hypercube of this length.</span>

            <span class="c1"># config for user specified P, R, rho_0, T. Examples here are for discrete spaces</span>
            <span class="c1"># config[&quot;transition_function&quot;] = np.array([[4 - i for i in range(config[&quot;state_space_size&quot;])] for j in range(config[&quot;action_space_size&quot;])]) #TODO ###IMP For all these prob. dist., there&#39;s currently a difference in what is returned for discrete vs continuous!</span>
            <span class="c1"># config[&quot;reward_function&quot;] = np.array([[4 - i for i in range(config[&quot;state_space_size&quot;])] for j in range(config[&quot;action_space_size&quot;])])</span>
            <span class="c1"># config[&quot;init_state_dist&quot;] = np.array([i/10 for i in range(config[&quot;state_space_size&quot;])])</span>
            <span class="c1"># config[&quot;terminal_states&quot;] = np.array([config[&quot;state_space_size&quot;] - 1]) # Can be discrete array or function to test terminal or not (e.g. for discrete and continuous spaces we may prefer 1 of the 2) #TODO currently always the same terminal state for a given environment state space size; have another variable named terminal_states to make semantic sense of variable name.</span>


            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;generate_random_mdp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1">###IMP # This supersedes previous settings and generates a random transition function, a random reward function (for random specific sequences)</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;delay&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;sequence_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;repeats_in_sequences&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_scale&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_density&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="c1"># Number between 0 and 1</span>
<span class="c1">#            config[&quot;transition_noise&quot;] = 0.2 # Currently the fractional chance of transitioning to one of the remaining states when given the deterministic transition function - in future allow this to be given as function; keep in mind that the transition function itself could be made a stochastic function - does that qualify as noise though?</span>
<span class="c1">#            config[&quot;reward_noise&quot;] = lambda a: a.normal(0, 0.1) #random #hack # a probability function added to reward function</span>
            <span class="c1"># config[&quot;transition_noise&quot;] = lambda a: a.normal(0, 0.1) #random #hack # a probability function added to transition function in cont. spaces</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;make_denser&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_state_density&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="c1"># Number between 0 and 1</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;maximally_connected&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Make every state reachable from every state; If maximally_connected, then no. of actions has to be at least equal to no. of states( - 1 if without self-loop); if repeating sequences allowed, then we have to have self-loops. Self-loops are ok even in non-repeating sequences - we just have a harder search problem then! Or make it maximally connected by having transitions to as many different states as possible - the row for P would have as many different transitions as possible!</span>
            <span class="c1"># print(config)</span>
            <span class="c1">#TODO asserts for the rest of the config settings</span>
            <span class="c1"># next: To implement delay, we can keep the previous observations to make state Markovian or keep an info bit in the state to denote that; Buffer length increase by fixed delay and fixed sequence length; current reward is incremented when any of the satisfying conditions (based on previous states) matches</span>

            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Print initial &quot;banner&quot;</span>
        <span class="n">screen_output_width</span> <span class="o">=</span> <span class="mi">132</span> <span class="c1">#hardcoded #TODO get from system</span>
        <span class="n">repeat_equal_sign</span> <span class="o">=</span> <span class="p">(</span><span class="n">screen_output_width</span> <span class="o">-</span> <span class="mi">20</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">set_ansi_escape</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[32;1m&quot;</span>
        <span class="n">reset_ansi_escape</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[0m&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">set_ansi_escape</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="n">repeat_equal_sign</span> <span class="o">+</span> <span class="s2">&quot;Initialising Toy MDP&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="n">repeat_equal_sign</span> <span class="o">+</span> <span class="n">reset_ansi_escape</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Current working directory:&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>

        <span class="c1"># Set other default settings for config to use if config is passed without any values for them</span>
        <span class="k">if</span> <span class="s2">&quot;log_level&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_level</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">CRITICAL</span> <span class="c1">#logging.NOTSET</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_level</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;log_level&quot;</span><span class="p">]</span>

        <span class="c1"># print(&#39;self.log_level&#39;, self.log_level)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_level</span><span class="p">)</span>
        <span class="c1"># fmtr = logging.Formatter(fmt=&#39;%(message)s - %(levelname)s - %(name)s - %(asctime)s&#39;, datefmt=&#39;%m.%d.%Y %I:%M:%S %p&#39;, style=&#39;%&#39;)</span>
        <span class="c1"># sh = logging.StreamHandler()</span>
        <span class="c1"># sh.setFormatter(fmt=fmtr)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="c1"># self.logger.addHandler(sh)</span>

        <span class="k">if</span> <span class="s2">&quot;log_filename&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
        <span class="c1">#     self.log_filename = __name__ + &#39;_&#39; + datetime.today().strftime(&#39;%m.%d.%Y_%I:%M:%S_%f&#39;) + &#39;.log&#39; #TODO Make a directoy &#39;log/&#39; and store there.</span>
        <span class="c1"># else:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">handlers</span><span class="p">:</span> <span class="c1"># checks that handlers is [], before adding a file logger, otherwise we would have multiple loggers to file if multiple RLToyEnvs were instantiated by the same process.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log_filename</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;log_filename&quot;</span><span class="p">]</span>
                <span class="c1"># logging.basicConfig(filename=&#39;/tmp/&#39; + self.log_filename, filemode=&#39;a&#39;, format=&#39;%(message)s - %(levelname)s - %(name)s - %(asctime)s&#39;, datefmt=&#39;%m.%d.%Y %I:%M:%S %p&#39;, level=self.log_level)</span>
                <span class="n">log_file_handler</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">FileHandler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_filename</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">log_file_handler</span><span class="p">)</span>
        <span class="c1"># log_filename = &quot;logs/output.log&quot;</span>
        <span class="c1"># os.makedirs(os.path.dirname(log_filename), exist_ok=True)</span>


        <span class="c1">#seed</span>
        <span class="k">if</span> <span class="s2">&quot;seed&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span> <span class="c1">#####IMP It&#39;s very important to not modify the config dict since it may be shared across multiple instances of the Env in the same process and could lead to very hard to catch bugs (I faced problems with Ray&#39;s A3C)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_int</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">need_to_gen_seeds</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span>
            <span class="n">need_to_gen_seeds</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="nb">int</span><span class="p">:</span> <span class="c1"># should be an int then. Gym doesn&#39;t accept np.int64, etc..</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_int</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span>
            <span class="n">need_to_gen_seeds</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unsupported data type for seed: &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]))</span>

        <span class="c1">#seed #TODO move to seed() so that obs., act. space, etc. have their seeds reset too when env seed is reset?</span>
        <span class="k">if</span> <span class="n">need_to_gen_seeds</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;env&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_int</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;env&quot;</span><span class="p">])</span>
            <span class="c1">##IMP All these diff. seeds may not be needed (you could have one seed for the joint relevant + irrelevant parts). But they allow for easy separation of the relevant and irrelevant dimensions!! _And_ the seed remaining the same for the underlying discrete environment makes it easier to write tests!</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;relevant_state_space&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;relevant_action_space&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;irrelevant_state_space&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;irrelevant_action_space&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;state_space&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#IMP This is currently used to sample only for continuous spaces and not used for discrete spaces by the Environment. User might want to sample from it for multi-discrete environments. #random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;action_space&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#IMP This IS currently used to sample random actions by the RL agent for both discrete and continuous environments (but not used anywhere by the Environment). #random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;image_representations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span><span class="p">)</span> <span class="c1">#random</span>
            <span class="c1"># print(&quot;Mersenne0, dummy_eval:&quot;, self.np_random.get_state()[2], &quot;dummy_eval&quot; in config)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># if seed dict was passed</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;env&quot;</span><span class="p">])</span>
            <span class="c1"># print(&quot;Mersenne0 (dict), dummy_eval:&quot;, self.np_random.get_state()[2], &quot;dummy_eval&quot; in config)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Seeds set to:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">))</span>
        <span class="c1"># print(f&#39;Seeds set to {self.seed_dict=}&#39;) # Available from Python 3.8</span>

        <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="c1">#defaults ###TODO throw warning in case unknown config option is passed</span>
        <span class="k">if</span> <span class="s2">&quot;use_custom_mdp&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;use_custom_mdp&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span>
                <span class="k">assert</span> <span class="s2">&quot;transition_function&quot;</span> <span class="ow">in</span> <span class="n">config</span>
                <span class="k">assert</span> <span class="s2">&quot;reward_function&quot;</span> <span class="ow">in</span> <span class="n">config</span>
                <span class="c1"># if config[&quot;state_space_type&quot;] == &quot;discrete&quot;:</span>
                <span class="c1">#     assert &quot;init_state_dist&quot; in config</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;generate_random_mdp&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_mdp</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">generate_random_mdp</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;generate_random_mdp&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;term_state_reward&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">term_state_reward</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">term_state_reward</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;term_state_reward&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;delay&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delay</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delay</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;delay&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_buffer</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;sequence_length&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;sequence_length&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;reward_density&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_density</span> <span class="o">=</span> <span class="mf">0.25</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_density</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_density&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;make_denser&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_denser</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">make_denser</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;make_denser&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;maximally_connected&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maximally_connected</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">maximally_connected</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;maximally_connected&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;reward_noise&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_noise&quot;</span><span class="p">]):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_noise</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_noise&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">reward_noise_std</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_noise&quot;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">reward_noise_std</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_noise</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="s2">&quot;transition_noise&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_noise&quot;</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_noise&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">p_noise_std</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_noise&quot;</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">p_noise_std</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># discrete case</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_noise&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># no transition noise</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="s2">&quot;reward_scale&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_scale</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_scale</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_scale&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;reward_shift&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_shift</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_shift</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_shift&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;irrelevant_features&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;irrelevant_features&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;image_representations&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_representations&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;image_transforms&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">,</span> <span class="s2">&quot;Image &quot;</span>\
                        <span class="s2">&quot;transforms are only applicable to discrete envs.&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_transforms</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_transforms&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_transforms</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span>

            <span class="k">if</span> <span class="s2">&quot;image_width&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_width</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_width&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_width</span> <span class="o">=</span> <span class="mi">100</span>

            <span class="k">if</span> <span class="s2">&quot;image_height&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_height</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_height&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">image_height</span> <span class="o">=</span> <span class="mi">100</span>

            <span class="c1"># The following transforms are only applicable in discrete envs:</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;image_sh_quant&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s1">&#39;shift&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transforms</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Setting image shift quantisation to the </span><span class="se">\</span>
<span class="s2">                        default of 1, since no config value was provided for it.&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">image_sh_quant</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">image_sh_quant</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">image_sh_quant</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_sh_quant&quot;</span><span class="p">]</span>

                <span class="k">if</span> <span class="s2">&quot;image_ro_quant&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s1">&#39;rotate&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transforms</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Setting image rotate quantisation to the </span><span class="se">\</span>
<span class="s2">                        default of 1, since no config value was provided for it.&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">image_ro_quant</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">image_ro_quant</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">image_ro_quant</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_ro_quant&quot;</span><span class="p">]</span>

                <span class="k">if</span> <span class="s2">&quot;image_scale_range&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s1">&#39;scale&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_transforms</span><span class="p">:</span>
                        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Setting image scale range to the default </span><span class="se">\</span>
<span class="s2">                        of (0.5, 1.5), since no config value was provided for it.&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">image_scale_range</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">image_scale_range</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">image_scale_range</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;image_scale_range&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;reward_dist&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_dist&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s2">&quot;diameter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;diameter&quot;</span><span class="p">]</span>

        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="c1"># if not self.use_custom_mdp:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_dim&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s2">&quot;transition_dynamics_order&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_dynamics_order&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s1">&#39;inertia&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inertia</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">inertia</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;inertia&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s1">&#39;time_unit&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_unit</span> <span class="o">=</span> <span class="mf">1.0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">time_unit</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;time_unit&quot;</span><span class="p">]</span>

            <span class="k">if</span> <span class="s1">&#39;target_radius&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_radius</span> <span class="o">=</span> <span class="mf">0.05</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_radius</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;target_radius&quot;</span><span class="p">]</span>

        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="s2">&quot;grid_shape&quot;</span> <span class="ow">in</span> <span class="n">config</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;grid_shape&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown state_space_type&quot;</span><span class="p">)</span>



        <span class="k">if</span> <span class="s2">&quot;action_loss_weight&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_loss_weight</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_loss_weight</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_loss_weight&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s2">&quot;reward_every_n_steps&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_every_n_steps</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_every_n_steps</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_every_n_steps&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="s1">&#39;repeats_in_sequences&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">repeats_in_sequences</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">repeats_in_sequences</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;repeats_in_sequences&#39;</span><span class="p">]</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span> <span class="k">if</span> <span class="s2">&quot;dtype&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span> <span class="k">else</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;dtype&quot;</span><span class="p">]</span>


        <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_space_size&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;Currently, 1st sub-state (and action) space is assumed to be relevant to rewards and 2nd one is irrelevant. Please provide a list with sizes for the 2.&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_space_size&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># uni-discrete space</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_space_size&quot;</span><span class="p">],</span> <span class="nb">int</span><span class="p">),</span> <span class="s2">&quot;Did you mean to turn irrelevant_features? If so, please set irrelevant_features = True in config. If not, please provide an int for action_space_size.&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span> <span class="o">=</span> <span class="p">[</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_space_size&quot;</span><span class="p">]]</span> <span class="c1"># Make a list to be able to iterate over observation spaces in for loops later</span>
                <span class="c1"># assert type(config[&quot;state_space_size&quot;]) == int, &#39;config[&quot;state_space_size&quot;] has to be provided as an int when we have a simple Discrete environment. Was:&#39; + str(type(config[&quot;state_space_size&quot;]))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span> <span class="o">=</span> <span class="p">[</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_size&quot;</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">diameter</span><span class="p">)</span>
                <span class="c1"># assert (np.array(self.state_space_size) % np.array(self.diameter) == 0).all(), &quot;state_space_size should be a multiple of the diameter to allow for the generation of regularly connected MDPs.&quot;</span>
        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="k">assert</span> <span class="s2">&quot;relevant_indices&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">,</span> <span class="s2">&quot;Please provide dimensions</span><span class="se">\</span>
<span class="s2">                 of state space relevant to rewards.&quot;</span>
            <span class="k">if</span> <span class="s2">&quot;relevant_indices&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">:</span>
                <span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span><span class="p">)</span>
            <span class="c1"># config[&quot;irrelevant_indices&quot;] = list(set(range(len(config[&quot;state_space_dim&quot;]))) - set(config[&quot;relevant_indices&quot;]))</span>
        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="c1"># Repeat the grid for the irrelevant part as well</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span> <span class="o">*</span> <span class="mi">2</span>




        <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;init_state_dist&quot;</span> <span class="ow">in</span> <span class="n">config</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;relevant_init_state_dist&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">config</span><span class="p">):</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_init_state_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;init_state_dist&quot;</span><span class="p">]</span>


        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;config[</span><span class="se">\&quot;</span><span class="s2">sequence_length</span><span class="se">\&quot;</span><span class="s2">] &lt;= 0. Set to: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">)</span> <span class="c1"># also should be int</span>
        <span class="k">if</span> <span class="s2">&quot;maximally_connected&quot;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;maximally_connected&quot;</span><span class="p">]:</span> <span class="c1">###TODO remove</span>
            <span class="k">pass</span>
            <span class="c1"># assert config[&quot;state_space_size&quot;] == config[&quot;action_space_size&quot;], &quot;config[\&quot;state_space_size\&quot;] != config[\&quot;action_space_size\&quot;]. For maximally_connected transition graphs, they should be equal. Please provide valid values. Vals: &quot; + str(config[&quot;state_space_size&quot;]) + &quot; &quot; + str(config[&quot;action_space_size&quot;]) + &quot;. In future, \&quot;maximally_connected\&quot; graphs are planned to be supported!&quot;</span>
            <span class="c1"># assert config[&quot;irrelevant_state_space_size&quot;] == config[&quot;irrelevant_action_space_size&quot;], &quot;config[\&quot;irrelevant_state_space_size\&quot;] != config[\&quot;irrelevant_action_space_size\&quot;]. For maximally_connected transition graphs, they should be equal. Please provide valid values! Vals: &quot; + str(config[&quot;irrelevant_state_space_size&quot;]) + &quot; &quot; + str(config[&quot;irrelevant_action_space_size&quot;]) + &quot;. In future, \&quot;maximally_connected\&quot; graphs are planned to be supported!&quot; #TODO Currently, irrelevant dimensions have a P similar to that of relevant dimensions. Should this be decoupled?</span>

        <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;continuous&#39;</span><span class="p">:</span>
            <span class="c1"># assert config[&quot;state_space_dim&quot;] == config[&quot;action_space_dim&quot;], &quot;For continuous spaces, state_space_dim has to be = action_space_dim. state_space_dim was: &quot; + str(config[&quot;state_space_dim&quot;]) + &quot; action_space_dim was: &quot; + str(config[&quot;action_space_dim&quot;])</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_to_a_point&quot;</span><span class="p">:</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;target_point&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]),),</span> <span class="s2">&quot;target_point should have dimensionality = relevant_state_space dimensionality&quot;</span>
        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_to_a_point&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;target_point&quot;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_episodes</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># This init_...() is done before the others below because it&#39;s needed</span>
        <span class="c1"># for image_representations for continuous</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_terminal_states</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span> <span class="o">=</span> <span class="p">[</span><span class="n">DiscreteExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;relevant_state_space&quot;</span><span class="p">])]</span>  <span class="c1">#seed #hardcoded, many time below as well</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span> <span class="o">=</span> <span class="p">[</span><span class="n">DiscreteExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;relevant_action_space&quot;</span><span class="p">])]</span>  <span class="c1">#seed #hardcoded</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DiscreteExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;irrelevant_state_space&quot;</span><span class="p">]))</span> <span class="c1">#seed #hardcoded</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DiscreteExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;irrelevant_action_space&quot;</span><span class="p">]))</span>  <span class="c1">#seed #hardcoded</span>
            <span class="c1"># Commented code below may used to generalise relevant sub-spaces to more than the current max of 2.</span>
            <span class="c1"># self.observation_spaces = [None] * len(config[&quot;all_indices&quot;])</span>
            <span class="c1"># for i in config[&quot;relevant_indices&quot;]:</span>
            <span class="c1">#     self.observation_spaces[i] =</span>
            <span class="c1">#     self.action_spaces[i] = DiscreteExtended(self.action_space_size[i], seed=self.seed_dict[&quot;relevant_action_space&quot;]) #seed</span>
            <span class="c1"># for i in config[&quot;irrelevant_indices&quot;]:</span>
            <span class="c1">#     self.observation_spaces[i] = DiscreteExtended(self.state_space_size[i], seed=self.seed_dict[&quot;irrelevant_state_space&quot;])) #seed # hack</span>
            <span class="c1">#     self.action_spaces[i] = DiscreteExtended(self.action_space_size[i], seed=self.seed_dict[&quot;irrelevant_action_space&quot;]) #seed</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span><span class="p">:</span>
                <span class="c1"># underlying_obs_space = MultiDiscreteExtended(self.state_space_size, seed=self.seed_dict[&quot;state_space&quot;]) #seed</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">ImageMultiDiscrete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_height</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_transforms</span><span class="p">,</span> <span class="n">sh_quant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_sh_quant</span><span class="p">,</span> <span class="n">scale_range</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_scale_range</span><span class="p">,</span> <span class="n">ro_quant</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_ro_quant</span><span class="p">,</span> <span class="n">circle_radius</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;image_representations&quot;</span><span class="p">])</span> <span class="c1">#seed</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">TupleExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;action_space&quot;</span><span class="p">])</span> <span class="c1">#seed</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">TupleExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;state_space&quot;</span><span class="p">])</span> <span class="c1">#seed # hack #TODO Gym (and so Ray) apparently needs observation_space as a member of an env.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">TupleExtended</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;action_space&quot;</span><span class="p">])</span> <span class="c1">#seed</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;continuous&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_max&quot;</span><span class="p">]</span> \
                    <span class="k">if</span> <span class="s1">&#39;state_space_max&#39;</span> <span class="ow">in</span> <span class="n">config</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># should we</span>
                    <span class="c1"># select a random max? #test?</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span> <span class="o">=</span> <span class="n">BoxExtended</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span><span class="p">,</span>\
                    <span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span><span class="p">,),</span>\
                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;state_space&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1">#seed</span>
                    <span class="c1"># hack #TODO # low and high are 1st 2 and required arguments</span>
                    <span class="c1"># for instantiating BoxExtended</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">action_space_max</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;action_space_max&quot;</span><span class="p">]</span> \
                    <span class="k">if</span> <span class="s1">&#39;action_space_max&#39;</span> <span class="ow">in</span> <span class="n">config</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1">#test?</span>
            <span class="c1"># config[&quot;action_space_max&quot;] = \</span>
            <span class="c1"># num_to_list(config[&quot;action_space_max&quot;]) * config[&quot;action_space_dim&quot;]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">BoxExtended</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_max</span><span class="p">,</span>\
                    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_max</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_dim</span><span class="p">,),</span>\
                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;action_space&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># #seed</span>
                    <span class="c1"># hack #TODO</span>


            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">ImageContinuous</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span><span class="p">,</span>\
                    <span class="n">width</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_height</span><span class="p">,</span> \
                    <span class="n">term_spaces</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">,</span> <span class="n">target_point</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">,</span>\
                    <span class="n">circle_radius</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;image_representations&quot;</span><span class="p">])</span> <span class="c1"># #seed</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span>

        <span class="k">elif</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="n">underlying_space_maxes</span> <span class="o">=</span> <span class="n">list_to_float_np_array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">)</span>


            <span class="c1"># The min for grid envs is 0, 0, 0, ...</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span> <span class="o">=</span> <span class="n">BoxExtended</span><span class="p">(</span><span class="mi">0</span> <span class="o">*</span> <span class="n">underlying_space_maxes</span><span class="p">,</span>\
                    <span class="n">underlying_space_maxes</span><span class="p">,</span>\
                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;state_space&quot;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># #seed</span>

            <span class="n">lows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">))</span>
            <span class="n">highs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">BoxExtended</span><span class="p">(</span><span class="n">lows</span><span class="p">,</span> <span class="n">highs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;action_space&quot;</span><span class="p">],</span>\
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="c1"># #seed</span>


            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span><span class="p">:</span>
                <span class="n">target_pt</span> <span class="o">=</span> <span class="n">list_to_float_np_array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">ImageContinuous</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span><span class="p">,</span>\
                    <span class="n">width</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_width</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">image_height</span><span class="p">,</span> \
                    <span class="n">term_spaces</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">,</span> <span class="n">target_point</span><span class="o">=</span><span class="n">target_pt</span><span class="p">,</span>\
                    <span class="n">circle_radius</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">grid_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">,</span>\
                    <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_dict</span><span class="p">[</span><span class="s2">&quot;image_representations&quot;</span><span class="p">])</span> <span class="c1"># #seed</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span>



        <span class="c1"># if config[&quot;action_space_type&quot;] == &quot;discrete&quot;:</span>
        <span class="c1">#     if not config[&quot;generate_random_mdp&quot;]:</span>
        <span class="c1">#         # self.logger.error(&quot;User defined P and R are currently not supported.&quot;) ##TODO</span>
        <span class="c1">#         # sys.exit(1)</span>
        <span class="c1">#         self.P = config[&quot;transition_function&quot;] if callable(config[&quot;transition_function&quot;]) else lambda s, a: config[&quot;transition_function&quot;][s, a] ##IMP callable may not be optimal always since it was deprecated in Python 3.0 and 3.1</span>
        <span class="c1">#         self.R = config[&quot;reward_function&quot;] if callable(config[&quot;reward_function&quot;]) else lambda s, a: config[&quot;reward_function&quot;][s, a]</span>
            <span class="c1"># else:</span>
        <span class="c1">##TODO Support imaginary rollouts for continuous envs. and user-defined P and R? Will do it depending on demand for it. In fact, for imagined rollouts, let our code handle storing augmented_state, curr_state, etc. in separate variables, so that it&#39;s easy for user to perform imagined rollouts instead of having to maintain their own state and action sequences.</span>
        <span class="c1">#TODO Generate state and action space sizes also randomly?</span>

        <span class="c1">###IMP The order in which the following inits are called is important, so don&#39;t change!!</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_init_state_dist</span><span class="p">()</span> <span class="c1">#init_state_dist: Initialises uniform distribution over non-terminal states for discrete distribution; After looking into Gym code, I can say that for continuous, it&#39;s uniform over non-terminal if limits are [a, b], shifted exponential if exactly one of the limits is np.inf, normal if both limits are np.inf - this sampling is independent for each dimension (and is done for the defined limits for the respective dimension).</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_transition_function</span><span class="p">()</span>
        <span class="c1"># print(&quot;Mersenne1, dummy_eval:&quot;, self.np_random.get_state()[2], &quot;dummy_eval&quot; in self.config)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_reward_function</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="c1">#TODO Maybe not call it here, since Gym seems to expect to _always_ call this method when using an environment; make this seedable? DO NOT do seed dependent initialization in reset() otherwise the initial state distrbution will always be at the same state at every call to reset()!! (Gym env has its own seed? Yes, it does, as does also space);</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;self.augmented_state, len: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;MDP Playground toy env instantiated with config: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MDP Playground toy env instantiated with config: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">))</span></div>


<div class="viewcode-block" id="RLToyEnv.init_terminal_states"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.init_terminal_states">[docs]</a>    <span class="k">def</span> <span class="nf">init_terminal_states</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialises terminal state set to be the &#39;last&#39; states for discrete environments. For continuous environments, terminal states will be in a hypercube centred around config[&#39;terminal_states&#39;] with the edge of the hypercube of length config[&#39;term_state_edge&#39;].</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span> <span class="ow">and</span> <span class="ow">not</span> <span class="s2">&quot;terminal_state_density&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="c1"># custom/user-defined terminal states</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">])</span> <span class="k">else</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Define the no. of terminal states per independent set of the state space</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_state_density&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1">#hardcoded ####IMP Using action_space_size since it contains state_space_size // diameter</span>
                <span class="c1"># if self.num_terminal_states == 0: # Have at least 1 terminal state?</span>
                <span class="c1">#     warnings.warn(&quot;WARNING: int(terminal_state_density * relevant_state_space_size) was 0. Setting num_terminal_states to be 1!&quot;)</span>
                <span class="c1">#     self.num_terminal_states = 1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">j</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">i</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span><span class="p">)])</span> <span class="c1"># terminal states inited to be at the &quot;end&quot; of the sorted states</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Inited terminal states to self.config[&#39;terminal_states&#39;]: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;. Total &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="c1"># print(&quot;# TODO for cont. spaces: term states&quot;)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">if</span> <span class="s1">&#39;terminal_states&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="c1">##TODO For continuous spaces, could also generate terminal spaces based on a terminal_state_density given by user (Currently, user specifies terminal state points around which hypercubes in state space are terminal. If the user want a specific density and not hypercubes, the user has to design the terminal states they specify such that they would have a given density in space.). But only for state spaces with limits? For state spaces without limits, could do it for a limited subspace of the inifinite state space 1st and then repeat that pattern indefinitely along each dimension&#39;s axis. #test?</span>
                <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">])):</span> <span class="c1"># List of centres of terminal state regions.</span>
                        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]),</span> <span class="s2">&quot;Specified terminal state centres should have dimensionality = number of relevant_indices. That was not the case for centre no.: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span>
                        <span class="n">lows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;term_state_edge&quot;</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]))])</span>
                        <span class="n">highs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;term_state_edge&quot;</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]))])</span>
                        <span class="c1"># print(&quot;Term state lows, highs:&quot;, lows, highs)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BoxExtended</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">lows</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">highs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span> <span class="c1">#seed #hack #TODO</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;self.term_spaces samples:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">()))</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">))])</span> <span class="c1">### TODO for cont. #test?</span>

            <span class="k">else</span><span class="p">:</span> <span class="c1"># no custom/user-defined terminal states</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="kc">False</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">if</span> <span class="s1">&#39;terminal_states&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">])):</span> <span class="c1"># List of</span>
                    <span class="c1"># terminal states on the grid</span>
                        <span class="n">term_state</span> <span class="o">=</span> <span class="n">list_to_float_np_array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;terminal_states&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
                        <span class="n">lows</span> <span class="o">=</span> <span class="n">term_state</span>
                        <span class="n">highs</span> <span class="o">=</span> <span class="n">term_state</span> <span class="c1"># #hardcoded</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BoxExtended</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">lows</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">highs</span><span class="p">,</span>\
                            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="c1">#seed #hack #TODO</span>

                    <span class="k">def</span> <span class="nf">is_term</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
                        <span class="n">cont_state</span> <span class="o">=</span> <span class="n">list_to_float_np_array</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
                        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">cont_state</span><span class="p">)</span> \
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">))])</span>


                    <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="n">is_term</span>

            <span class="k">else</span><span class="p">:</span> <span class="c1"># no custom/user-defined terminal states</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="kc">False</span></div>


<div class="viewcode-block" id="RLToyEnv.init_init_state_dist"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.init_init_state_dist">[docs]</a>    <span class="k">def</span> <span class="nf">init_init_state_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialises initial state distrbution, rho_0, to be uniform over the non-terminal states for discrete environments. For both discrete and continuous environments, the uniform sampling over non-terminal states is taken care of in reset() when setting the initial state for an episode.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># relevant dimensions part</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span> <span class="ow">and</span> <span class="s2">&quot;init_state_dist&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="c1"># custom/user-defined phi_0</span>
                <span class="c1"># self.config[&quot;relevant_init_state_dist&quot;] = #TODO make this also a lambda function?</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># For relevant sub-space</span>
                <span class="n">non_term_state_space_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span> <span class="c1">#hardcoded</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_init_state_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">non_term_state_space_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">non_term_state_space_size</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span><span class="p">)])</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span> <span class="c1">#TODO Currently only uniform distribution over non-terminal states; Use Dirichlet distribution to select prob. distribution to use?</span>
                <span class="c1">#TODO make init_state_dist the default sample() for state space?</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_init_state_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_init_state_dist&quot;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;self.relevant_init_state_dist:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_init_state_dist&quot;</span><span class="p">]))</span>

                <span class="c1">#irrelevant sub-space</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                    <span class="n">non_term_state_space_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">#hardcoded</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;irrelevant_init_state_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">([</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">non_term_state_space_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">non_term_state_space_size</span><span class="p">)])</span> <span class="c1"># diameter not needed here as we directly take the state_space_size in the prev. line</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;irrelevant_init_state_dist&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;irrelevant_init_state_dist&quot;</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;self.irrelevant_init_state_dist:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;irrelevant_init_state_dist&quot;</span><span class="p">]))</span>

        <span class="k">else</span><span class="p">:</span> <span class="c1"># if continuous or grid space</span>
            <span class="k">pass</span> <span class="c1"># this is handled in reset where we resample if we sample a term. state</span></div>


<div class="viewcode-block" id="RLToyEnv.init_transition_function"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.init_transition_function">[docs]</a>    <span class="k">def</span> <span class="nf">init_transition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialises transition function, P by selecting random next states for every (state, action) tuple for discrete environments. For continuous environments, we have 1 option for the transition function which varies depending on dynamics order and inertia and time_unit for a point object.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span> <span class="c1"># custom/user-defined P</span>
                <span class="c1">#</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># relevant dimensions part</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span> <span class="c1">#hardcoded</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">][:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1">#IMP # To avoid having a valid value from the state space before we actually assign a usable value below!</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximally_connected</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="c1">#hack # TODO Remove this if block; this case is currently separately handled just so that tests do not fail. Using prob=prob in the sample call causes the sampling to change even if the probabilities remain the same. All solutions I can think of are hacky except changing the expected values in all the test cases which would take quite some time.</span>
                        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#random #TODO Preferably use the seed of the Env for this? #hardcoded</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># if diam &gt; 1</span>
                        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                            <span class="n">i_s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># select the current independent set number</span>

                            <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
                            <span class="n">prob_next_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="n">ind_1</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="n">ind_2</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="c1"># print(ind_1, ind_2)</span>
                            <span class="k">if</span> <span class="n">ind_2</span> <span class="o">&lt;=</span> <span class="n">ind_1</span><span class="p">:</span> <span class="c1"># edge case</span>
                                <span class="n">ind_2</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="n">prob</span><span class="p">[</span><span class="n">ind_1</span> <span class="p">:</span> <span class="n">ind_2</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob_next_states</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#random #TODO Preferably use the seed of the Env for this? #hardcoded</span>

                            <span class="c1"># hacky way to do the above</span>
                            <span class="c1"># self.config[&quot;transition_function&quot;][s] = self.observation_spaces[0].sample(max=self.action_space_size[0], size=self.action_space_size[0], replace=False) #random #TODO Preferably use the seed of the Env for this? #hardcoded</span>
                            <span class="c1"># Set the transitions from current state to be to the next independent set&#39;s states</span>
                            <span class="c1"># self.config[&quot;transition_function&quot;][s] += ((i_s + 1) * self.action_space_size[0]) % self.state_space_size[0]</span>
                <span class="k">else</span><span class="p">:</span> <span class="c1"># if not maximally_connected</span>
                    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                        <span class="n">i_s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># select the current independent set number</span>

                        <span class="c1"># Set the probabilities of the next state for the current independent set</span>
                        <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
                        <span class="n">prob_next_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">ind_1</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">ind_2</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="c1"># print(ind_1, ind_2)</span>
                        <span class="k">if</span> <span class="n">ind_2</span> <span class="o">&lt;=</span> <span class="n">ind_1</span><span class="p">:</span> <span class="c1"># edge case</span>
                            <span class="n">ind_2</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">prob</span><span class="p">[</span><span class="n">ind_1</span> <span class="p">:</span> <span class="n">ind_2</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob_next_states</span>

                        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                            <span class="c1"># prob[i_s * self.action_space_size[0] : (i_s + 1) * self.action_space_size[0]] = prob_next_states</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">][</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">)</span> <span class="c1">#random #TODO Preferably use the seed of the Env for this?</span>
                <span class="c1"># Set the next state for terminal states to be themselves, for any action taken.</span>
                <span class="k">for</span> <span class="n">i_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">diameter</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span><span class="p">(</span><span class="n">i_s</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span> <span class="o">==</span> <span class="kc">True</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">][</span><span class="n">i_s</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="n">i_s</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">s</span> <span class="c1"># Setting P(s, a) = s for terminal states, for P() to be meaningful even if someone doesn&#39;t check for &#39;done&#39; being = True</span>


                <span class="c1">#irrelevant dimensions part</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span> <span class="c1">#test</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">][:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1">#IMP # To avoid having a valid value from the state space before we actually assign a usable value below!</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maximally_connected</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                            <span class="n">i_s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># select the current independent set number</span>

                            <span class="c1"># Set the probabilities of the next state for the current independent set</span>
                            <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
                            <span class="n">prob_next_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">ind_1</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">ind_2</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="nb">print</span><span class="p">(</span><span class="n">ind_1</span><span class="p">,</span> <span class="n">ind_2</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">ind_2</span> <span class="o">&lt;=</span> <span class="n">ind_1</span><span class="p">:</span> <span class="c1"># edge case</span>
                                <span class="n">ind_2</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">prob</span><span class="p">[</span><span class="n">ind_1</span> <span class="p">:</span> <span class="n">ind_2</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob_next_states</span>

                            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#random #TODO Preferably use the seed of the Env for this? #hardcoded</span>

                            <span class="c1"># self.config[&quot;transition_function_irrelevant&quot;][s] = self.observation_spaces[1].sample(max=self.action_space_size[1], size=self.action_space_size[1], replace=False) #random #TODO Preferably use the seed of the Env for this?</span>
                            <span class="c1"># self.config[&quot;transition_function_irrelevant&quot;][s] += ((i_s + 1) * self.action_space_size[1]) % self.state_space_size[1]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                            <span class="n">i_s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># select the current independent set number</span>

                            <span class="c1"># Set the probabilities of the next state for the current independent set</span>
                            <span class="n">prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
                            <span class="n">prob_next_states</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">ind_1</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">ind_2</span> <span class="o">=</span> <span class="p">((</span><span class="n">i_s</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="c1"># print(ind_1, ind_2)</span>
                            <span class="k">if</span> <span class="n">ind_2</span> <span class="o">&lt;=</span> <span class="n">ind_1</span><span class="p">:</span> <span class="c1"># edge case</span>
                                <span class="n">ind_2</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                            <span class="n">prob</span><span class="p">[</span><span class="n">ind_1</span> <span class="p">:</span> <span class="n">ind_2</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob_next_states</span>

                            <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                                <span class="c1"># prob[i_s * self.action_space_size[1] : (i_s + 1) * self.action_space_size[1]] = prob_next_states</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">][</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="n">prob</span><span class="p">)</span> <span class="c1">#random #TODO Preferably use the seed of the Env for this?</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;init_transition_function _irrelevant&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])))</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">]):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">transition_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;transition_matrix inited to:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transition_matrix</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Python type of state: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">](</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))))</span> <span class="c1"># The Python type of the state can lead to hard to catch bugs</span>

        <span class="k">else</span><span class="p">:</span> <span class="c1"># if continuous or grid space</span>
            <span class="c1"># self.logger.debug(&quot;# TODO for cont. spaces&quot;) # transition function is a fixed parameterisation for cont. envs. right now.</span>
            <span class="k">pass</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_function</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span></div>

<div class="viewcode-block" id="RLToyEnv.init_reward_function"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.init_reward_function">[docs]</a>    <span class="k">def</span> <span class="nf">init_reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialises reward function, R by selecting random sequences to be rewardable for discrete environments. For continuous environments, we have fixed available options for the reward function.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># print(&quot;Mersenne2, dummy_eval:&quot;, self.np_random.get_state()[2], &quot;dummy_eval&quot; in self.config)</span>

        <span class="c1">#TODO Maybe refactor this code and put useful reusable permutation generators, etc. in one library</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span> <span class="c1"># custom/user-defined R</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_matrix</span><span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">a</span><span class="p">]</span> <span class="c1">#hardcoded to be 2nd last state in state sequence passed to reward function, so that reward is R(s, a) when transition is s, a, r, s&#39;</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;reward_matrix inited to:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_matrix</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">non_term_state_space_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_terminal_states</span>

                <span class="k">def</span> <span class="nf">get_sequences</span><span class="p">(</span><span class="n">maximum</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">fraction</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">diameter</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
                    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">                    Returns random sequences of integers</span>

<span class="sd">                    maximum: int</span>
<span class="sd">                        Max value of the integers in the sequence</span>
<span class="sd">                    length: int</span>
<span class="sd">                        Length of sequence</span>
<span class="sd">                    fraction: float</span>
<span class="sd">                        Fraction of total possible sequences to be returned</span>
<span class="sd">                    repeats: boolean</span>
<span class="sd">                        Allows repeats in returned sequences</span>
<span class="sd">                    diameter: int</span>
<span class="sd">                        Relates to the diameter of the MDP</span>
<span class="sd">                    &#39;&#39;&#39;</span>

                    <span class="n">sequences</span> <span class="o">=</span> <span class="p">[]</span>

                    <span class="k">if</span> <span class="n">repeats</span><span class="p">:</span>
                        <span class="n">num_possible_sequences</span> <span class="o">=</span> <span class="p">(</span><span class="n">maximum</span><span class="p">)</span> <span class="o">**</span> <span class="n">length</span>
                        <span class="n">num_sel_sequences</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fraction</span> <span class="o">*</span> <span class="n">num_possible_sequences</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">num_sel_sequences</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">num_sel_sequences</span> <span class="o">=</span> <span class="mi">1</span>
                            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;0 rewardable sequences per independent set for given reward_density, sequence_length, diameter and terminal_state_density. Setting it to 1.&#39;</span><span class="p">)</span>
                        <span class="n">sel_sequence_nums</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_possible_sequences</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_sel_sequences</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#random # This assumes that all sequences have an equal likelihood of being selected for being a reward sequence; This line also makes it not possible to have this function be portable as part of a library because it use the np_random member variable of this class</span>
                        <span class="k">for</span> <span class="n">i_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">diameter</span><span class="p">):</span> <span class="c1"># Allow sequences to begin in any of the independent sets and therefore this loop is over the no. of independent sets(= diameter)</span>
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sel_sequences</span><span class="p">):</span>
                                <span class="n">curr_sequence_num</span> <span class="o">=</span> <span class="n">sel_sequence_nums</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                                <span class="n">specific_sequence</span> <span class="o">=</span> <span class="p">[]</span>
                                <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">specific_sequence</span><span class="p">)</span> <span class="o">!=</span> <span class="n">length</span><span class="p">:</span>
                                    <span class="n">specific_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_sequence_num</span> <span class="o">%</span> <span class="p">(</span><span class="n">non_term_state_space_size</span><span class="p">)</span> <span class="o">+</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">specific_sequence</span><span class="p">)</span> <span class="o">+</span> <span class="n">i_s</span><span class="p">)</span> <span class="o">%</span> <span class="n">diameter</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1">#TODO this uses a member variable of the class. Add another function param to receive this value? Name it independent set size?</span>
                                    <span class="n">curr_sequence_num</span> <span class="o">=</span> <span class="n">curr_sequence_num</span> <span class="o">//</span> <span class="p">(</span><span class="n">non_term_state_space_size</span><span class="p">)</span>
                                    <span class="c1">#bottleneck When we sample sequences here, it could get very slow if reward_density is high; alternative would be to assign numbers to sequences and then sample these numbers without replacement and take those sequences</span>
                                    <span class="c1"># specific_sequence = self.relevant_observation_space.sample(size=self.sequence_length, replace=True) # Be careful that sequence_length is less than state space size</span>
                                <span class="n">sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">specific_sequence</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Total no. of rewarded sequences:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="s2">&quot;Out of&quot;</span><span class="p">,</span> <span class="n">num_possible_sequences</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;per independent set&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># if no repeats</span>
                        <span class="k">assert</span> <span class="n">length</span> <span class="o">&lt;=</span> <span class="n">diameter</span> <span class="o">*</span> <span class="n">maximum</span><span class="p">,</span> <span class="s2">&quot;When there are no repeats in sequences, the sequence length should be &lt;= diameter * maximum.&quot;</span>
                        <span class="n">permutations</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">length</span><span class="p">):</span>
                            <span class="n">permutations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">maximum</span> <span class="o">-</span> <span class="n">i</span> <span class="o">//</span> <span class="n">diameter</span><span class="p">)</span>
                        <span class="c1"># permutations = list(range(maximum + 1 - length, maximum + 1))</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No. of choices for each element in a possible sequence (Total no. of permutations will be a product of this), no. of possible perms per independent set: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">permutations</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">permutations</span><span class="p">)))</span>

                        <span class="k">for</span> <span class="n">i_s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">diameter</span><span class="p">):</span> <span class="c1"># Allow sequences to begin in any of the independent sets and therefore this loop is over the no. of independent sets(= diameter). Could maybe sample independent set no. as &quot;part&quot; of sel_sequence_nums below and avoid this loop?</span>
                            <span class="n">num_possible_permutations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">permutations</span><span class="p">)</span> <span class="c1"># Number of possible permutations/sequences for, say, a diameter of 3 and 24 total states and terminal_state_density = 0.25, i.e., 6 non-terminal states (out of 8 states) per independent set, for sequence length of 5 is np.prod([6, 6, 6, 5, 5]) * 3; the * diameter at the end is needed because the sequence can begin in any of the independent sets; However, for simplicity, we omit * diameter here and just perform the same procedure per independent set. This can lead to slightly fewer rewardable sequences than should be the case for a given reward_density - this is due int() in the next step</span>
                            <span class="n">num_sel_sequences</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fraction</span> <span class="o">*</span> <span class="n">num_possible_permutations</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">num_sel_sequences</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1">##TODO Remove this test here and above?</span>
                                <span class="n">num_sel_sequences</span> <span class="o">=</span> <span class="mi">1</span>
                                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;0 rewardable sequences per independent set for given reward_density, sequence_length, diameter and terminal_state_density. Setting it to 1.&#39;</span><span class="p">)</span>
                            <span class="c1"># print(&quot;Mersenne3:&quot;, self.np_random.get_state()[2])</span>
                            <span class="n">sel_sequence_nums</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">num_possible_permutations</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_sel_sequences</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1">#random # This assumes that all sequences have an equal likelihood of being selected for being a reward sequence; # TODO this code could be replaced with self.np_random.permutation(non_term_state_space_size)[self.sequence_length]? Replacement becomes a problem then! We have to keep sampling until we have all unique rewardable sequences.</span>
                            <span class="c1"># print(&quot;Mersenne4:&quot;, self.np_random.get_state()[2])</span>

                            <span class="n">total_clashes</span> <span class="o">=</span> <span class="mi">0</span>
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sel_sequences</span><span class="p">):</span>
                                <span class="n">curr_permutation</span> <span class="o">=</span> <span class="n">sel_sequence_nums</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                                <span class="n">seq_</span> <span class="o">=</span> <span class="p">[]</span>
                                <span class="n">curr_rem_digits</span> <span class="o">=</span> <span class="p">[]</span>
                                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">diameter</span><span class="p">):</span>
                                    <span class="n">curr_rem_digits</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">maximum</span><span class="p">)))</span> <span class="c1"># has to contain every number up to n so that any one of them can be picked as part of the sequence below</span>
                                <span class="k">for</span> <span class="n">enum</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">permutations</span><span class="p">):</span> <span class="c1"># Goes from largest to smallest number among the factors of nPk</span>
                                    <span class="n">rem_</span> <span class="o">=</span> <span class="n">curr_permutation</span> <span class="o">%</span> <span class="n">j</span>
                                    <span class="c1"># rem_ = (enum // maximum) * maximum + rem_</span>
                                    <span class="n">seq_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_rem_digits</span><span class="p">[(</span><span class="n">enum</span> <span class="o">+</span> <span class="n">i_s</span><span class="p">)</span> <span class="o">%</span> <span class="n">diameter</span><span class="p">][</span><span class="n">rem_</span><span class="p">]</span> <span class="o">+</span> <span class="p">((</span><span class="n">enum</span> <span class="o">+</span> <span class="n">i_s</span><span class="p">)</span> <span class="o">%</span> <span class="n">diameter</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># Use (enum + i_s) to allow other independent sets to have states beginning a rewardable sequence</span>
                                    <span class="k">del</span> <span class="n">curr_rem_digits</span><span class="p">[(</span><span class="n">enum</span> <span class="o">+</span> <span class="n">i_s</span><span class="p">)</span> <span class="o">%</span> <span class="n">diameter</span><span class="p">][</span><span class="n">rem_</span><span class="p">]</span>
                            <span class="c1">#         print(&quot;curr_rem_digits&quot;, curr_rem_digits)</span>
                                    <span class="n">curr_permutation</span> <span class="o">=</span> <span class="n">curr_permutation</span> <span class="o">//</span> <span class="n">j</span>

                                <span class="k">if</span> <span class="n">seq_</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">:</span> <span class="c1">#hack</span>
                                    <span class="n">total_clashes</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1">#TODO remove these extra checks and assert below</span>
                                <span class="n">sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_</span><span class="p">)</span>

                            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Number of generated sequences that did not clash with an existing one when it was generated:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">total_clashes</span><span class="p">))</span>
                            <span class="k">assert</span> <span class="n">total_clashes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;None of the generated sequences should have clashed with an existing rewardable sequence when it was generated. No. of times a clash was detected:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">total_clashes</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Total no. of rewarded sequences:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot;Out of&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_possible_permutations</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;per independent set&quot;</span><span class="p">)</span>

                    <span class="k">return</span> <span class="n">sequences</span>

                <span class="k">def</span> <span class="nf">insert_sequence</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
                    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">                    Inserts rewardable sequences into the rewardable_sequences dict member variable</span>
<span class="sd">                    &#39;&#39;&#39;</span>
                    <span class="n">sequence</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="c1"># tuples are immutable and can be used as keys for a dict</span>
                    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">[</span><span class="n">sequence</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">[</span><span class="n">sequence</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># this is the default reward value, reward scaling will be handled later</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;specific_sequence that will be rewarded&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sequence</span><span class="p">))</span> <span class="c1">#TODO impose a different distribution for these: independently sample state for each step of specific sequence; or conditionally dependent samples if we want something like DMPs/manifolds</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_denser</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">ss_len</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)):</span>
                            <span class="n">sub_sequence</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">sequence</span><span class="p">[:</span><span class="n">ss_len</span><span class="p">])</span>
                            <span class="k">if</span> <span class="n">sub_sequence</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">[</span><span class="n">sub_sequence</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">[</span><span class="n">sub_sequence</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">[</span><span class="n">sequence</span><span class="p">]</span> <span class="o">*</span> <span class="n">ss_len</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="c1"># this could cause problems if we support variable sequence lengths and there are clashes in selected rewardable sequences</span>


                <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">repeats_in_sequences</span><span class="p">:</span>
                    <span class="n">rewardable_sequences</span> <span class="o">=</span> <span class="n">get_sequences</span><span class="p">(</span><span class="n">maximum</span><span class="o">=</span><span class="n">non_term_state_space_size</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">fraction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_density</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">diameter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">diameter</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span> <span class="c1"># if no repeats_in_sequences</span>
                    <span class="n">rewardable_sequences</span> <span class="o">=</span> <span class="n">get_sequences</span><span class="p">(</span><span class="n">maximum</span><span class="o">=</span><span class="n">non_term_state_space_size</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="n">fraction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_density</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">diameter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">diameter</span><span class="p">)</span>

                <span class="c1"># Common to both cases: repeats_in_sequences or not</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span> <span class="c1"># Specified as interval</span>
                    <span class="n">reward_dist_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span>
                    <span class="n">num_rews</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">diameter</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewardable_sequences</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;num_rewardable_sequences set to:&quot;</span><span class="p">,</span> <span class="n">num_rews</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">num_rews</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">rews</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">rews</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">reward_dist_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reward_dist_</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num</span><span class="o">=</span><span class="n">num_rews</span><span class="p">)</span>
                    <span class="k">assert</span> <span class="n">rews</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mf">1.0</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">rews</span><span class="p">)</span>

                    <span class="k">def</span> <span class="nf">get_rews</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">r_dict</span><span class="p">):</span>
                        <span class="k">return</span> <span class="n">rews</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">r_dict</span><span class="p">)]</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">reward_dist</span> <span class="o">=</span> <span class="n">get_rews</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">rewardable_sequences</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Too many rewardable sequences and/or too long rewardable sequence length. Environment might be too slow. Please consider setting the reward_density to be lower or reducing the sequence length. No. of rewardable sequences:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rewardable_sequences</span><span class="p">)))</span> <span class="c1">#TODO Maybe even exit the program if too much memory is (expected to be) taken.; Took about 80s for 40k iterations of the for loop below on my laptop</span>

                <span class="k">for</span> <span class="n">specific_sequence</span> <span class="ow">in</span> <span class="n">rewardable_sequences</span><span class="p">:</span>
                    <span class="n">insert_sequence</span><span class="p">(</span><span class="n">specific_sequence</span><span class="p">)</span>
                <span class="c1"># else: # &quot;repeats&quot; in sequences are allowed until diameter - 1 steps have been taken: We sample the sequences as the state number inside each independent set, which are numbered from 0 to action_space_size - 1</span>
                <span class="c1">#     pass</span>

                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;rewardable_sequences: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">))</span> <span class="c1">#debug print</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="c1"># self.logger.debug(&quot;# TODO for cont. spaces?: init_reward_function&quot;) # reward functions are fixed for cont. right now with a few available choices.</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="o">...</span> <span class="c1"># ###TODO Make sequences compatible with grid</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_function</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span></div>


<div class="viewcode-block" id="RLToyEnv.transition_function"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.transition_function">[docs]</a>    <span class="k">def</span> <span class="nf">transition_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The transition function, P.</span>

<span class="sd">        Performs a transition according to the initialised P for discrete environments (with dynamics independent for relevant vs irrelevant dimension sub-spaces). For continuous environments, we have a fixed available option for the dynamics (which is the same for relevant or irrelevant dimensions):</span>
<span class="sd">        The order of the system decides the dynamics. For an nth order system, the nth order derivative of the state is set to the action value / inertia for time_unit seconds. And then the dynamics are integrated over the time_unit to obtain the next state.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        state : list</span>
<span class="sd">            The state that the environment will use to perform a transition.</span>
<span class="sd">        action : list</span>
<span class="sd">            The action that the environment will use to perform a transition.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or np.array</span>
<span class="sd">            The state at the end of the current transition</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">](</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span><span class="p">:</span>
                <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">probs</span><span class="p">[</span><span class="n">next_state</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span>
                <span class="c1"># TODO Samples according to new probs to get noisy discrete transition</span>
                <span class="n">new_next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span> <span class="c1">#random</span>
                <span class="c1"># print(&quot;noisy old next_state, new_next_state&quot;, next_state, new_next_state)</span>
                <span class="k">if</span> <span class="n">next_state</span> <span class="o">!=</span> <span class="n">new_next_state</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;NOISE inserted! old next_state, new_next_state&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_next_state</span><span class="p">))</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">total_noisy_transitions_episode</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="c1"># print(&quot;new probs:&quot;, probs, self.relevant_observation_space.sample(prob=probs))</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">new_next_state</span>
                <span class="c1"># assert np.sum(probs) == 1, str(np.sum(probs)) + &quot; is not equal to &quot; + str(1)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="c1">##TODO implement imagined transitions also for cont. spaces</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function&quot;</span><span class="p">](</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;Action should be specified as a 1-D tensor. However, shape of action was: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_dim</span><span class="p">,</span> <span class="s1">&#39;Action shape is: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;. Expected: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space_dim</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
                    <span class="c1">### TODO implement for multiple orders, currently only for 1st order systems.</span>
                    <span class="c1"># if self.dynamics_order == 1:</span>
                    <span class="c1">#     next_state = state + action * self.time_unit / self.inertia</span>

                    <span class="c1"># print(&#39;self.state_derivatives:&#39;, self.state_derivatives)</span>
                    <span class="c1"># Except the last member of state_derivatives, the other occupy the same place in memory. Could create a new copy of them every time, but I think this should be more efficient and as long as tests don&#39;t fail should be fine.</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">action</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">inertia</span> <span class="c1"># action is presumed to be n-th order force ##TODO Could easily scale this per dimension to give different kinds of dynamics per dimension: maybe even sample this scale per dimension from a probability distribution to generate different random Ps?</span>
                    <span class="n">factorial_array</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">factorial</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># This is just to speed things up as scipy calculates the factorial only for largest array member</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span><span class="p">):</span>
                        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span> <span class="o">-</span> <span class="n">i</span><span class="p">):</span>
                            <span class="c1"># print(&#39;i, j, self.state_derivatives, (self.time_unit**(j + 1)), factorial_array:&#39;, i, j, self.state_derivatives, (self.time_unit**(j + 1)), factorial_array)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">time_unit</span><span class="o">**</span><span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">factorial_array</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="c1">#+state_derivatives_prev[i] Don&#39;t need to add previous value as it&#39;s already in there at the beginning ##### TODO Keep an old self.state_derivatives and a new one otherwise higher order derivatives will be overwritten before being used by lower order ones.</span>
                    <span class="c1"># print(&#39;self.state_derivatives:&#39;, self.state_derivatives)</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

                <span class="k">else</span><span class="p">:</span> <span class="c1"># if action is from outside allowed action_space</span>
                    <span class="n">next_state</span> <span class="o">=</span> <span class="n">state</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;WARNING: Action &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; out of range of action space. Applying 0 action!!&quot;</span><span class="p">)</span>
            <span class="c1"># if &quot;transition_noise&quot; in self.config:</span>
            <span class="n">noise_in_transition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="k">else</span> <span class="mi">0</span> <span class="c1">#random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">total_abs_noise_in_transition_episode</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">noise_in_transition</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">+=</span> <span class="n">noise_in_transition</span> <span class="c1">##IMP Noise is only applied to state and not to higher order derivatives</span>
            <span class="c1">### TODO Check if next_state is within state space bounds</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">next_state</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;next_state out of bounds. next_state, clipping to&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span><span class="p">)))</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_max</span><span class="p">)</span> <span class="c1"># Could also &quot;reflect&quot; next_state when it goes out of bounds. Would seem more logical for a &quot;wall&quot;, but would need to take care of multiple reflections near a corner/edge.</span>
                <span class="c1"># Resets all higher order derivatives to 0</span>
                <span class="n">zero_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="c1"># #####IMP to have copy() otherwise it&#39;s the same array</span>
                <span class="c1"># (in memory) at every position in the list:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span> <span class="o">=</span> <span class="p">[</span><span class="n">zero_state</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_state</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_to_a_point&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_radius</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reached_terminal</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="c1"># state passed and returned is an np.array</span>
            <span class="c1"># Need to check that dtype is int because Gym doesn&#39;t</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="ow">and</span> \
                            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span><span class="p">:</span>
                    <span class="c1"># self.np_random.choice only works for 1-D arrays</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span><span class="p">:</span> <span class="c1"># #random</span>
                        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span> <span class="c1"># Be careful of infinite loops</span>
                            <span class="n">new_action</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span> <span class="c1"># #random</span>
                            <span class="k">if</span> <span class="n">new_action</span> <span class="o">!=</span> <span class="n">action</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;NOISE inserted! old action, new_action&quot;</span> <span class="o">+</span>\
                                        <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_action</span><span class="p">))</span>
                                <span class="c1"># print(str(action) + str(new_action))</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">total_noisy_transitions_episode</span> <span class="o">+=</span> <span class="mi">1</span>
                                <span class="n">action</span> <span class="o">=</span> <span class="n">new_action</span>
                                <span class="k">break</span>

                <span class="n">next_state</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">)):</span>
                    <span class="c1"># actions -1, 0, 1 represent back, noop, forward respt.</span>
                    <span class="n">next_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">action</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">next_state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Underflow in grid next state. Bouncing back.&quot;</span><span class="p">)</span>
                        <span class="n">next_state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

                    <span class="k">if</span> <span class="n">next_state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Overflow in grid next state. Bouncing back.&quot;</span><span class="p">)</span>
                        <span class="n">next_state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grid_shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="k">else</span><span class="p">:</span> <span class="c1"># if action is from outside allowed action_space</span>
                <span class="n">next_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;WARNING: Action &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; out of range&quot;</span>\
                <span class="s2">&quot; of action space. Applying noop action!!&quot;</span><span class="p">)</span>


            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_to_a_point&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span> <span class="o">==</span> <span class="n">next_state</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">reached_terminal</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>


        <span class="k">return</span> <span class="n">next_state</span></div>

<div class="viewcode-block" id="RLToyEnv.reward_function"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.reward_function">[docs]</a>    <span class="k">def</span> <span class="nf">reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The reward function, R.</span>

<span class="sd">        Rewards the sequences selected to be rewardable at initialisation for discrete environments. For continuous environments, we have fixed available options for the reward function:</span>
<span class="sd">            move_to_a_point rewards for moving to a predefined location. It has sparse and dense settings.</span>
<span class="sd">            move_along_a_line rewards moving along ANY direction in space as long as it&#39;s a fixed direction for sequence_length consecutive steps.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        state : list</span>
<span class="sd">            The underlying MDP state (also called augmented state in this code) that the environment uses to calculate its reward. Normally, just the sequence of past states of length delay + sequence_length + 1.</span>
<span class="sd">        action : single action dependent on action space</span>
<span class="sd">            Action magnitudes are penalised immediately in the case of continuous spaces and, in effect, play no role for discrete spaces as the reward in that case only depends on sequences of states. We say &quot;in effect&quot; because it _is_ used in case of a custom R to calculate R(s, a) but that is equivalent to using the &quot;next&quot; state s&#39; as the reward determining criterion in case of deterministic transitions. _Sequences_ of _actions_ are currently NOT used to calculate the reward. Since the underlying MDP dynamics are deterministic, a state and action map 1-to-1 with the next state and so, just a sequence of _states_ should be enough to calculate the reward.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        double</span>
<span class="sd">            The reward at the end of the current transition</span>

<span class="sd">        #TODO Make reward depend on the action sequence too instead of just state sequence, as it is currently?</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay</span>
        <span class="n">sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># print(&quot;TEST&quot;, self.augmented_state[0 : self.augmented_state_length - delay], state, action, self.rewardable_sequences, type(state), type(self.rewardable_sequences))</span>
        <span class="n">state_considered</span> <span class="o">=</span> <span class="n">state</span> <span class="c1"># if imaginary_rollout else self.augmented_state # When we imagine a rollout, the user has to provide full augmented state as the argument!!</span>
        <span class="c1"># if not isinstance(state_considered, list):</span>
        <span class="c1">#     state_considered = [state_considered] # to get around case when sequence is an int; it should always be a list except if a user passes in a state; would rather force them to pass a list: assert for it!!</span>
        <span class="c1"># TODO These asserts are only needed if imaginary_rollout is True, as users then pass in a state sequence</span>
        <span class="c1"># if imaginary_rollout:</span>
        <span class="c1">#     assert isinstance(state_considered, list), &quot;state passed in should be a list of states containing at the very least the state at beginning of the transition, s, and the one after it, s&#39;. type was: &quot; + str(type(state_considered))</span>
        <span class="c1">#     assert len(state_considered) == self.augmented_state_length, &quot;Length of list of states passed should be equal to self.augmented_state_length. It was: &quot; + str(len(state_considered))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_mdp</span><span class="p">:</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">](</span><span class="n">state_considered</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward_buffer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span> <span class="c1">##TODO Modify seq_len and delay code for discrete and continuous case to use buffer too?</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># print(&quot;rewards:&quot;, self.reward_buffer, old_reward, reward)</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">state_considered</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="k">pass</span> <span class="c1">###IMP: This check is to get around case of augmented_state_length being &gt; 2, i.e. non-vanilla seq_len or delay, because then rewards may be handed out for the initial state being part of a sequence which is not fair since it is handed out without having the agent take an action.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;state_considered for reward:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">state_considered</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; with delay &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay</span><span class="p">))</span>
                <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_every_n_steps</span> <span class="ow">or</span>
                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward_every_n_steps</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_transitions_episode</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">==</span> <span class="n">delay</span><span class="p">)):</span> <span class="c1">###TODO also implement this for make_denser case and continuous envs.</span>
                    <span class="n">sub_seq</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">state_considered</span><span class="p">[</span><span class="mi">1</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state_length</span> <span class="o">-</span> <span class="n">delay</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">sub_seq</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">:</span>
                        <span class="c1"># print(state_considered, &quot;with delay&quot;, self.delay, &quot;rewarded with:&quot;, 1)</span>
                        <span class="n">reward</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewardable_sequences</span><span class="p">[</span><span class="n">sub_seq</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># print(state_considered, &quot;with delay&quot;, self.delay, &quot;NOT rewarded.&quot;)</span>
                        <span class="k">pass</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;rew&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">reward</span><span class="p">))</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="c1">##TODO Make reward for along a line case to be length of line travelled - sqrt(Sum of Squared distances from the line)? This should help with keeping the mean reward near 0. Since the principal component is always taken to be the direction of travel, this would mean a larger distance covered in that direction and hence would lead to +ve reward always and would mean larger random actions give a larger reward! Should penalise actions in proportion that scale then?</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">state_considered</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]):</span> <span class="c1"># Instead of below commented out check, this is more robust for imaginary transitions</span>
            <span class="c1"># if self.total_transitions_episode + 1 &lt; self.augmented_state_length: # + 1 because augmented_state_length is always 1 greater than seq_len + del</span>
                <span class="k">pass</span> <span class="c1">#TODO</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_along_a_line&quot;</span><span class="p">:</span>
                    <span class="c1"># print(&quot;######reward test&quot;, self.total_transitions_episode, np.array(self.augmented_state), np.array(self.augmented_state).shape)</span>
                    <span class="c1">#test: 1. for checking 0 distance for same action being always applied; 2. similar to 1. but for different dynamics orders; 3. similar to 1 but for different action_space_dims; 4. for a known applied action case, check manually the results of the formulae and see that programmatic results match: should also have a unit version of 4. for dist_of_pt_from_line() and an integration version here for total_deviation calc.?.</span>
                    <span class="n">data_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)[</span><span class="mi">1</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state_length</span> <span class="o">-</span> <span class="n">delay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]]</span>
                    <span class="n">data_mean</span> <span class="o">=</span> <span class="n">data_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">uu</span><span class="p">,</span> <span class="n">dd</span><span class="p">,</span> <span class="n">vv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">data_</span> <span class="o">-</span> <span class="n">data_mean</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;uu.shape, dd.shape, vv.shape =&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">uu</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">dd</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">vv</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
                    <span class="n">line_end_pts</span> <span class="o">=</span> <span class="n">vv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="c1"># vv[0] = 1st eigenvector, corres. to Principal Component #hardcoded -100 to 100 to get a &quot;long&quot; line which should make calculations more robust(?: didn&#39;t seem to be the case for 1st few trials, so changed it to -1, 1; even tried up to 10000 - seems to get less precise for larger numbers) to numerical issues in dist_of_pt_from_line() below; newaxis added so that expected broadcasting takes place</span>
                    <span class="n">line_end_pts</span> <span class="o">+=</span> <span class="n">data_mean</span>

                    <span class="n">total_deviation</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="k">for</span> <span class="n">data_pt</span> <span class="ow">in</span> <span class="n">data_</span><span class="p">:</span> <span class="c1"># find total distance of all data points from the fit line above</span>
                        <span class="n">total_deviation</span> <span class="o">+=</span> <span class="n">dist_of_pt_from_line</span><span class="p">(</span><span class="n">data_pt</span><span class="p">,</span> <span class="n">line_end_pts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">line_end_pts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;total_deviation of pts from fit line:&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">total_deviation</span><span class="p">))</span>

                    <span class="n">reward</span> <span class="o">+=</span> <span class="p">(</span> <span class="o">-</span> <span class="n">total_deviation</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="p">)</span>

                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_to_a_point&quot;</span><span class="p">:</span> <span class="c1"># Could generate target points randomly but leaving it to the user to do that. #TODO Generate it randomly to have random Rs?</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_denser</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="n">old_relevant_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span> <span class="o">-</span> <span class="n">delay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]]</span>
                        <span class="n">new_relevant_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]]</span>
                        <span class="n">reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">new_relevant_state</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">)</span> <span class="c1"># Should allow other powers of the distance from target_point, or more norms?</span>
                        <span class="n">reward</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">old_relevant_state</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">)</span> <span class="c1"># Reward is the distance moved towards the target point.</span>
                        <span class="c1"># Should rather be the change in distance to target point, so reward given is +ve if &quot;correct&quot; action was taken and so reward function is more natural (this _is_ the current implementation)</span>
                        <span class="c1"># It&#39;s true that giving the total -ve distance from target as the loss at every step gives a stronger signal to algorithm to make it move faster towards target but this seems more natural (as in the other case loss/reward go up quadratically with distance from target point while in this case it&#39;s linear). The value function is in both cases higher for states further from target. But isn&#39;t that okay? Since the greater the challenge (i.e. distance from target), the greater is the achieved overall reward at the end.</span>
                        <span class="c1">#TODO To enable seq_len, we can hand out reward if distance to target point is reduced (or increased - since that also gives a better signal than giving 0 in that case!!) for seq_len consecutive steps, otherwise 0 reward - however we need to hand out fixed reward for every &quot;sequence&quot; achieved otherwise, if we do it by adding the distance moved towards target in the sequence, it leads to much bigger rewards for larger seq_lens because of overlapping consecutive sequences.</span>
                        <span class="c1"># TODO also make_denser, sparse rewards only at target</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># sparse reward</span>
                        <span class="n">new_relevant_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delay</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_indices&quot;</span><span class="p">]]</span>
                        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">new_relevant_state</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_radius</span><span class="p">:</span>
                            <span class="n">reward</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># Make the episode terminate as well? Don&#39;t need to. If algorithm is smart enough, it will stay in the radius and earn more reward.</span>

                    <span class="n">reward</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_loss_weight</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;reward_function&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;move_to_a_point&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_denser</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="n">old_relevant_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span> <span class="o">-</span> <span class="n">delay</span><span class="p">]</span>
                    <span class="n">new_relevant_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delay</span><span class="p">]</span>

                    <span class="n">manhat_dist_old</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">cityblock</span><span class="p">(</span><span class="n">old_relevant_state</span><span class="p">,</span>\
                                            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">))</span>
                    <span class="n">manhat_dist_new</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">cityblock</span><span class="p">(</span><span class="n">new_relevant_state</span><span class="p">,</span>\
                                            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">))</span>

                    <span class="n">reward</span> <span class="o">+=</span> <span class="n">manhat_dist_old</span> <span class="o">-</span> <span class="n">manhat_dist_new</span>

                <span class="k">else</span><span class="p">:</span> <span class="c1"># sparse reward</span>
                    <span class="n">new_relevant_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">state_considered</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">delay</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">new_relevant_state</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_point</span><span class="p">:</span>
                        <span class="n">reward</span> <span class="o">+=</span> <span class="mf">1.0</span>

        <span class="n">reward</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_scale</span>
        <span class="n">noise_in_reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_noise</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_noise</span> <span class="k">else</span> <span class="mi">0</span> <span class="c1">#random ###TODO Would be better to parameterise this in terms of state, action and time_step as well. Would need to change implementation to have a queue for the rewards achieved and then pick the reward that was generated delay timesteps ago.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_abs_noise_in_reward_episode</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">noise_in_reward</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_reward_episode</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">reward</span> <span class="o">+=</span> <span class="n">noise_in_reward</span>
        <span class="n">reward</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_shift</span>
        <span class="k">return</span> <span class="n">reward</span></div>

<div class="viewcode-block" id="RLToyEnv.step"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">imaginary_rollout</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The step function for the environment.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        action : int or np.array</span>
<span class="sd">            The action that the environment will use to perform a transition.</span>
<span class="sd">        imaginary_rollout: boolean</span>
<span class="sd">            Option for the user to perform &quot;imaginary&quot; transitions, e.g., for model-based RL. If set to true, underlying augmented state of the MDP is not changed and user is responsible to maintain and provide a list of states to this function to be able to perform a rollout.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or np.array, double, boolean, dict</span>
<span class="sd">            The next state, reward, whether the episode terminated and additional info dict at the end of the current transition</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># For imaginary transitions, discussion:</span>
        <span class="c1"># 1) Use external observation_space as argument to P() and R(). But then it&#39;s not possible for P and R to know underlying MDP state unless we pass it as another argument. This is not desirable as we want P and R to simply be functions of external state/observation and action. 2) The other possibility is how it&#39;s currently done: P and R _know_ the underlying state. But in this case, we need an extra imaginary_rollout argument to P and R and we can&#39;t perform imaginary rollouts longer than one step without asking the user to maintain a sequence of underlying states and actions to be passed as arguments to P and R.</span>
        <span class="c1"># P and R knowing the underlying state seems a poor design choice to me because it makes the code structure more brittle, so I propose that step() handles the underlying state vs external observation conversion and user can use P and R with underlying state. And step should handle the case of imaginary rollouts by building a tree of transitions and allowing rollback to states along the tree. However, user will probably want access to P and R by using only observations as well instead of the underlying state. In this case, P and R need to be aware of underlying state and be able to store imaginary rollouts if needed.</span>


        <span class="c1"># Transform multi-discrete to discrete for discrete state spaces with irrelevant dimensions; needed only for imaginary rollouts, otherwise, internal augmented state is used.</span>

        <span class="k">if</span> <span class="n">imaginary_rollout</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Imaginary rollouts are currently not supported.&quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">state_irrelevant</span><span class="p">,</span> <span class="n">action_irrelevant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">action</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">state</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">,</span> <span class="n">action</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># cont. or grid case</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">,</span> <span class="n">action</span>


        <span class="c1">### TODO Decide whether to give reward before or after transition (&quot;after&quot; would mean taking next state into account and seems more logical to me) - make it a dimension? - R(s) or R(s, a) or R(s, a, s&#39;)? I&#39;d say give it after and store the old state in the augmented_state to be able to let the R have any of the above possible forms. That would also solve the problem of implicit 1-step delay with giving it before. _And_ would not give any reward for already being in a rewarding state in the 1st step but _would_ give a reward if 1 moved to a rewardable state - even if called with R(s, a) because s&#39; is stored in the augmented_state! #####IMP</span>

        <span class="n">next_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span> <span class="c1">###TODO P uses last state while R uses augmented state; for cont. env, P does know underlying state_derivatives - we don&#39;t want this to be the case for the imaginary rollout scenario;</span>

        <span class="c1"># if imaginary_rollout:</span>
        <span class="c1">#     pass</span>
        <span class="c1">#     # print(&quot;imaginary_rollout&quot;) # Since transition_function currently depends only on current state and action, we don&#39;t need to do anything here!</span>
        <span class="c1"># else:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_state</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">next_state</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_transitions_episode</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">,</span> <span class="n">action</span><span class="p">)</span>

        <span class="c1">#irrelevant dimensions part</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="n">next_state_irrelevant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;transition_function_irrelevant&quot;</span><span class="p">][</span><span class="n">state_irrelevant</span><span class="p">,</span> <span class="n">action_irrelevant</span><span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span><span class="p">:</span>
                    <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">probs</span><span class="p">[</span><span class="n">next_state_irrelevant</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition_noise</span>
                    <span class="n">new_next_state_irrelevant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span> <span class="c1">#random</span>
                    <span class="c1"># if next_state_irrelevant != new_next_state_irrelevant:</span>
                    <span class="c1">#     print(&quot;NOISE inserted! old next_state_irrelevant, new_next_state_irrelevant&quot;, next_state_irrelevant, new_next_state_irrelevant)</span>
                    <span class="c1">#     self.total_noisy_transitions_irrelevant_episode += 1</span>
                    <span class="n">next_state_irrelevant</span> <span class="o">=</span> <span class="n">new_next_state_irrelevant</span>


        <span class="c1"># Transform discrete back to multi-discrete if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_state</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">next_state_irrelevant</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_state</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># cont. or grid space</span>
            <span class="n">next_obs</span> <span class="o">=</span> <span class="n">next_state</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span><span class="p">:</span>
            <span class="n">next_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">get_concatenated_image</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span> <span class="o">=</span> <span class="n">next_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span> <span class="o">=</span> <span class="n">next_obs</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">reached_terminal</span> <span class="c1">#### TODO curr_state is external state, while we need to check relevant state for terminality! Done - by using augmented_state now instead of curr_state!</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reward</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">term_state_reward</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_scale</span> <span class="c1"># Scale before or after?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;sas</span><span class="se">\&#39;</span><span class="s1">r:   &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;   &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;   &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;   &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_augmented_state</span><span class="p">()</span></div>

<div class="viewcode-block" id="RLToyEnv.get_augmented_state"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.get_augmented_state">[docs]</a>    <span class="k">def</span> <span class="nf">get_augmented_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Intended to return the full augmented state which would be Markovian. (However, it&#39;s not Markovian wrt the noise in P and R because we&#39;re not returning the underlying RNG.) Currently, returns the augmented state which is the sequence of length &quot;delay + sequence_length + 1&quot; of past states for both discrete and continuous environments. Additonally, the current state derivatives are also returned for continuous environments.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        dict</span>
<span class="sd">            Contains at the end of the current transition</span>

<span class="sd">        #TODO For noisy processes, this would need the noise distribution and random seed too. Also add the irrelevant state parts, etc.? We don&#39;t need the irrelevant parts for the state to be Markovian.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="n">augmented_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;curr_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">,</span> <span class="s2">&quot;curr_obs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span><span class="p">,</span> <span class="s2">&quot;augmented_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">}</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="n">augmented_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;curr_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">,</span> <span class="s2">&quot;curr_obs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span><span class="p">,</span> <span class="s2">&quot;augmented_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">,</span> <span class="s2">&quot;state_derivatives&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">}</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="n">augmented_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;curr_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">,</span> \
                                    <span class="s2">&quot;curr_obs&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span><span class="p">,</span> \
                                    <span class="s2">&quot;augmented_state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="p">}</span>

        <span class="k">return</span> <span class="n">augmented_state_dict</span></div>


<div class="viewcode-block" id="RLToyEnv.reset"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;Resets the environment for the beginning of an episode and samples a start state from rho_0. For discrete environments uses the defined rho_0 directly. For continuous environments, samples a state and resamples until a non-terminal state is sampled.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or np.array</span>
<span class="sd">            The start state for a new episode.</span>
<span class="sd">        &#39;&#39;&#39;</span>

        <span class="c1"># on episode &quot;end&quot; stuff (to not be invoked when reset() called when self.total_episodes = 0; end is in quotes because it may not be a true episode end reached by reaching a terminal state, but reset() may have been called in the middle of an episode):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">total_episodes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Noise stats for previous episode num.: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_episodes</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; (total abs. noise in rewards, total abs. noise in transitions, total reward, total noisy transitions, total transitions): &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_abs_noise_in_reward_episode</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_abs_noise_in_transition_episode</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_reward_episode</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_noisy_transitions_episode</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_transitions_episode</span><span class="p">))</span>

        <span class="c1"># on episode start stuff:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reward_buffer</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_episodes</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;discrete&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;relevant_init_state_dist&quot;</span><span class="p">])</span> <span class="c1">#random</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span> <span class="c1"># curr_state set here already in case if statement below is not entered</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">irrelevant_features</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">curr_state_irrelevant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;irrelevant_init_state_dist&quot;</span><span class="p">])</span> <span class="c1">#random</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state_irrelevant</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;RESET called. Relevant part of state reset to:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Irrelevant part of state reset to:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state_irrelevant</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span><span class="p">)</span>
            <span class="c1"># self.augmented_state = np.array(self.augmented_state) # Do NOT make an np.array out of it because we want to test existence of the array in an array of arrays which is not possible with np.array!</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;continuous&quot;</span><span class="p">:</span>
            <span class="c1"># self.logger.debug(&quot;#TODO for cont. spaces: reset&quot;)</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span> <span class="c1"># Be careful about infinite loops</span>
                <span class="n">term_space_was_sampled</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="c1">#random</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">):</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">)):</span> <span class="c1"># Could this sampling be made more efficient? In general, the non-terminal space could have any shape and assiging equal sampling probability to each point in this space is pretty hard.</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">term_spaces</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">):</span>
                            <span class="n">j</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;A state was sampled in term state subspace. Therefore, resampling. State was, subspace was:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="c1">##TODO Move this logic into a new class in Gym spaces that can contain subspaces for term states! (with warning/error if term subspaces cover whole state space, or even a lot of it)</span>
                    <span class="n">term_space_was_sampled</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="c1"># break</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">term_space_was_sampled</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="c1"># if not self.use_custom_mdp:</span>
            <span class="c1"># init the state derivatives needed for continuous spaces</span>
            <span class="n">zero_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span> <span class="o">=</span> <span class="p">[</span><span class="n">zero_state</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dynamics_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="c1">#####IMP to have copy() otherwise it&#39;s the same array (in memory) at every position in the list</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state_derivatives</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span> <span class="o">=</span> <span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_space_dim</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">augmented_state_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;state_space_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;grid&quot;</span><span class="p">:</span>
            <span class="c1"># Need to set self.curr_state, self.augmented_state</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span> <span class="c1"># Be careful about infinite loops</span>
                <span class="n">term_space_was_sampled</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="c1"># curr_state is an np.array while curr_state_relevant is a list</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> <span class="c1"># #random</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span> <span class="c1"># #hardcoded</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_terminal_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;A terminal state was sampled. Therefore,&quot;</span>\
                    <span class="s2">&quot; resampling. State was:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">))</span>
                    <span class="n">term_space_was_sampled</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">term_space_was_sampled</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span>\
                                        <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">augmented_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state_relevant</span><span class="p">)</span>



        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_representations</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">get_concatenated_image</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;RESET called. curr_state reset to: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">curr_state</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reached_terminal</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">total_abs_noise_in_reward_episode</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_abs_noise_in_transition_episode</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># only present in continuous spaces</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_noisy_transitions_episode</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># only present in discrete spaces</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_reward_episode</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_transitions_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; self.delay, self.sequence_length:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">curr_obs</span></div>

<div class="viewcode-block" id="RLToyEnv.seed"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.RLToyEnv.html#mdp_playground.envs.rl_toy_env.RLToyEnv.seed">[docs]</a>    <span class="k">def</span> <span class="nf">seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialises the Numpy RNG for the environment by calling a utility for this in Gym.</span>

<span class="sd">        The environment has its own RNG and so do the state and action spaces held by the environment.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        seed : int</span>
<span class="sd">            seed to initialise the np_random instance held by the environment. Cannot use numpy.int64 or similar because Gym doesn&#39;t accept it.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The seed returned by Gym</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If seed is None, you get a randomly generated seed from gym.utils...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">np_random</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">seeding</span><span class="o">.</span><span class="n">np_random</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="c1">#random</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Env SEED set to: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;. Returned seed from Gym: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed_</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed_</span></div></div>


<div class="viewcode-block" id="dist_of_pt_from_line"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.dist_of_pt_from_line.html#mdp_playground.envs.rl_toy_env.dist_of_pt_from_line">[docs]</a><span class="k">def</span> <span class="nf">dist_of_pt_from_line</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">ptA</span><span class="p">,</span> <span class="n">ptB</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Returns shortest distance of a point from a line defined by 2 points - ptA and ptB. Based on: https://softwareengineering.stackexchange.com/questions/168572/distance-from-point-to-n-dimensional-line</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">tolerance</span> <span class="o">=</span> <span class="mf">1e-13</span>
    <span class="n">lineAB</span> <span class="o">=</span> <span class="n">ptA</span> <span class="o">-</span> <span class="n">ptB</span>
    <span class="n">lineApt</span> <span class="o">=</span> <span class="n">ptA</span> <span class="o">-</span> <span class="n">pt</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">lineAB</span><span class="p">,</span> <span class="n">lineApt</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">lineAB</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">proj</span> <span class="o">=</span> <span class="n">dot_product</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">lineAB</span><span class="p">)</span> <span class="c1">#### TODO could lead to division by zero if line is a null vector!</span>
        <span class="n">sq_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">lineApt</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">proj</span><span class="o">**</span><span class="mi">2</span>

        <span class="k">if</span> <span class="n">sq_dist</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sq_dist</span> <span class="o">&lt;</span> <span class="n">tolerance</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;The squared distance calculated in dist_of_pt_from_line() using Pythagoras</span><span class="se">\&#39;</span><span class="s1"> theorem was less than the tolerance allowed. It was: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sq_dist</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;. Tolerance was: -&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tolerance</span><span class="p">))</span> <span class="c1"># logging.warn() has been deprecated since Python 3.3 and we should use logging.warning.</span>
            <span class="n">sq_dist</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sq_dist</span><span class="p">)</span>
    <span class="c1">#     print(&#39;pt, ptA, ptB, lineAB, lineApt, dot_product, proj, dist:&#39;, pt, ptA, ptB, lineAB, lineApt, dot_product, proj, dist)</span>
        <span class="k">return</span> <span class="n">dist</span></div>

<div class="viewcode-block" id="list_to_float_np_array"><a class="viewcode-back" href="../../../_autosummary/mdp_playground.envs.rl_toy_env.list_to_float_np_array.html#mdp_playground.envs.rl_toy_env.list_to_float_np_array">[docs]</a><span class="k">def</span> <span class="nf">list_to_float_np_array</span><span class="p">(</span><span class="n">lis</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Converts list to numpy float array</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">lis</span><span class="p">))</span></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>

    <span class="n">config</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">config</span><span class="p">[</span><span class="s2">&quot;seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1">#seed, 7 worked for initially sampling within term state subspace</span>

    <span class="c1"># Simple discrete environment usage example</span>
    <span class="c1"># config[&quot;state_space_type&quot;] = &quot;discrete&quot;</span>
    <span class="c1"># config[&quot;state_space_size&quot;] = 6</span>
    <span class="c1"># config[&quot;action_space_size&quot;] = 6</span>
    <span class="c1"># config[&quot;reward_density&quot;] = 0.25 # Number between 0 and 1</span>
    <span class="c1"># config[&quot;make_denser&quot;] = True</span>
    <span class="c1"># config[&quot;terminal_state_density&quot;] = 0.25 # Number between 0 and 1</span>
    <span class="c1"># config[&quot;maximally_connected&quot;] = True # Make every state reachable from every state</span>
    <span class="c1"># config[&quot;repeats_in_sequences&quot;] = False</span>
    <span class="c1"># config[&quot;delay&quot;] = 1</span>
    <span class="c1"># config[&quot;sequence_length&quot;] = 3</span>
    <span class="c1"># config[&quot;reward_scale&quot;] = 1.0</span>
    <span class="c1"># # config[&quot;transition_noise&quot;] = 0.2 # Currently the fractional chance of transitioning to one of the remaining states when given the deterministic transition function - in future allow this to be given as function; keep in mind that the transition function itself could be made a stochastic function - does that qualify as noise though?</span>
    <span class="c1"># # config[&quot;reward_noise&quot;] = lambda a: a.normal(0, 0.1) #random #hack # a probability function added to reward function</span>

    <span class="c1"># Simple continuous environment usage example</span>
    <span class="c1"># config[&quot;state_space_type&quot;] = &quot;continuous&quot;</span>
    <span class="c1"># config[&quot;state_space_dim&quot;] = 2</span>
    <span class="c1"># config[&quot;action_space_dim&quot;] = 2</span>
    <span class="c1"># config[&quot;transition_dynamics_order&quot;] = 1</span>
    <span class="c1"># config[&quot;inertia&quot;] = 1 # 1 unit, e.g. kg for mass, or kg * m^2 for moment of inertia.</span>
    <span class="c1"># config[&quot;state_space_max&quot;] = 5 # Will be a Box in the range [-max, max]</span>
    <span class="c1"># config[&quot;action_space_max&quot;] = 1 # Will be a Box in the range [-max, max]</span>
    <span class="c1"># config[&quot;time_unit&quot;] = 1 # Discretization of time domain</span>
    <span class="c1"># config[&quot;terminal_states&quot;] = [[0.0, 1.0], [1.0, 0.0]]</span>
    <span class="c1"># config[&quot;term_state_edge&quot;] =  1.0 # Terminal states will be in a hypercube centred around the terminal states given above with the edge of the hypercube of this length.</span>
    <span class="c1">#</span>
    <span class="c1"># config[&quot;delay&quot;] = 1</span>
    <span class="c1"># config[&quot;sequence_length&quot;] = 10</span>
    <span class="c1"># config[&quot;reward_scale&quot;] = 1.0</span>
    <span class="c1"># # config[&quot;reward_noise&quot;] = lambda a: a.normal(0, 0.1) #random #hack # a probability function added to reward function</span>
    <span class="c1"># # config[&quot;transition_noise&quot;] = lambda a: a.normal(0, 0.1) #random #hack # a probability function added to transition function in cont. spaces</span>
    <span class="c1"># config[&quot;reward_function&quot;] = &quot;move_along_a_line&quot;</span>

    <span class="n">config</span><span class="p">[</span><span class="s2">&quot;generate_random_mdp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># This supersedes previous settings and generates a random transition function, a random reward function (for random specific sequences)</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">RLToyEnv</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">get_augmented_state</span><span class="p">()[</span><span class="s1">&#39;curr_state&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
        <span class="c1"># env.render() # For GUI</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="c1"># take a #random action</span>
        <span class="c1"># action = np.array([1, 1, 1, 1]) # just to test if acting &quot;in a line&quot; works</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sars&#39;, done =&quot;</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># import sys</span>
    <span class="c1"># sys.exit(0)</span>
</pre></div>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By MDP Playground developers<br/>
        
            &copy; Copyright 2021, MDP Playground developers.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>