{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup to analyse an MDP Playground experiment\n",
    "from mdp_playground.analysis import MDPP_Analysis\n",
    "# Set dir_name to the location where the CSV files from running an experiment were saved\n",
    "dir_name = '/home/rajanr/mdpp_12579179' # 12348452, 12354801, 12362352, 12495380, 12499228, 12500667, 12503823, 12505701, 12506870, 12532831, 12536403, 12540214, 12546339, 12550729, 12552121, 12578498, 12578770, 12579037, 12579179\n",
    "# Set exp_name to the name that was given to the experiment when running it\n",
    "exp_name = 'a3c_image_representations_tune_hps'\n",
    "# Set the following to True to save PDFs of plots that you generate below\n",
    "save_fig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "mdpp_analysis = MDPP_Analysis()\n",
    "train_stats, eval_stats, train_curves, eval_curves = mdpp_analysis.load_data(dir_name, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D: Plots showing reward after 20k timesteps when varying a single meta-feature\n",
    "# Plots across 10 runs: Training: with std dev across the runs\n",
    "mdpp_analysis.plot_1d_dimensions(train_stats, save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots across 10 runs: Evaluation: with std dev across the runs\n",
    "mdpp_analysis.plot_1d_dimensions(eval_stats, save_fig, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-D heatmap plots across 10 runs: Training runs: with std dev across the runs\n",
    "# There seems to be a bug with matplotlib - x and y axes tick labels are not correctly set even though we pass them. Please feel free to look into the code and suggest a correction if you find it.\n",
    "mdpp_analysis.plot_2d_heatmap(train_stats, save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2-D heatmap plots across 10 runs: Evaluation runs: with std dev across the runs\n",
    "mdpp_analysis.plot_2d_heatmap(eval_stats, save_fig, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves: Training: Each curve corresponds to a different seed for the agent\n",
    "mdpp_analysis.plot_learning_curves(train_curves, save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves: Evaluation: Each curve corresponds to a different seed for the agent\n",
    "mdpp_analysis.plot_learning_curves(eval_curves, save_fig, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some more analysis\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr as spm\n",
    "from scipy.stats import pearsonr as prs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dir_name_config = 'experiments/'\n",
    "file_ = dir_name_config + exp_name\n",
    "\n",
    "config_file_path = os.path.abspath('/'.join(file_.split('/')[:-1]))\n",
    "# print(file_.split('/')[:-1])\n",
    "print(\"config_file_path:\", config_file_path)\n",
    "sys.path.insert(1, config_file_path) #hack\n",
    "import importlib\n",
    "config = importlib.import_module(file_.split('/')[-1], package=None)\n",
    "print(\"Number of seeds for environment:\", config.num_seeds)\n",
    "\n",
    "value_tuples = []\n",
    "for config_type, config_dict in config.var_configs.items():\n",
    "    for key in config_dict:\n",
    "        if 'seed' in key:\n",
    "            print(key)\n",
    "            pass\n",
    "        else:\n",
    "            assert type(config.var_configs[config_type][key]) == list, \"var_config should be a dict of dicts with lists as the leaf values to allow each configuration option to take multiple possible values\"\n",
    "            value_tuples.append(config.var_configs[config_type][key])\n",
    "\n",
    "import itertools\n",
    "cartesian_product_configs = list(itertools.product(*value_tuples))\n",
    "print(\"Total number of configs. to run:\", len(cartesian_product_configs))\n",
    "print(mdpp_analysis.axis_labels)\n",
    "# import itertools\n",
    "# cartesian_product_configs = list(itertools.product(*config_vals))\n",
    "for i in range(len(train_stats.shape)):\n",
    "    if train_stats.shape[i] > 1:\n",
    "        dummy_seeds_axis = i\n",
    "        break\n",
    "print(\"dummy_seeds_axis:\", dummy_seeds_axis, len(train_stats.shape))\n",
    "mean_data_eval = np.mean(eval_stats[..., -2], axis=dummy_seeds_axis)\n",
    "std_data_ = np.std(eval_stats[..., -2], axis=dummy_seeds_axis)\n",
    "\n",
    "def analysis(train_stats):\n",
    "    mean_data_ = np.mean(train_stats[..., -2], axis=dummy_seeds_axis)\n",
    "    std_data_ = np.std(train_stats[..., -2], axis=dummy_seeds_axis)\n",
    "    print(mean_data_.shape, train_stats[..., -2].shape)\n",
    "    flattened_mean = np.ravel(mean_data_)\n",
    "    flattened_std = np.ravel(std_data_)\n",
    "    ranks = np.argsort(flattened_mean)[::-1]\n",
    "    print('sort of indices:\\n', ranks)\n",
    "    ranks_with_std = np.argsort(flattened_mean - flattened_std)[::-1]\n",
    "    print('sort of indices (with std taken into account):\\n', ranks_with_std)\n",
    "    sorted_vals = np.sort(flattened_mean)[::-1]\n",
    "    print('sort of values:\\n', sorted_vals)\n",
    "    sorted_vals_with_std = np.sort(flattened_mean - flattened_std)[::-1]\n",
    "    print('sort of values (with std taken into account):\\n', sorted_vals_with_std)\n",
    "    print(\"TOP 3 configs (with std taken into account):\\n\")\n",
    "    print(cartesian_product_configs[np.argsort(flattened_mean - flattened_std)[-1]]) \n",
    "    print(cartesian_product_configs[np.argsort(flattened_mean - flattened_std)[-2]])\n",
    "    print(cartesian_product_configs[np.argsort(flattened_mean - flattened_std)[-3]])\n",
    "    plt.figure(figsize=(30, 1.5))\n",
    "    plt.bar([i for i in range(len(flattened_mean))], flattened_mean, yerr=flattened_std)\n",
    "    plt.show()\n",
    "    return flattened_mean, flattened_mean - flattened_std\n",
    "    \n",
    "sorted_vals_t, sorted_vals_with_std_t = analysis(train_stats)\n",
    "sorted_vals_e, sorted_vals_with_std_e = analysis(eval_stats)\n",
    "print(spm(sorted_vals_t, sorted_vals_e))\n",
    "print(spm(sorted_vals_t, sorted_vals_with_std_t))\n",
    "print(spm(sorted_vals_with_std_t, sorted_vals_with_std_e))\n",
    "print(spm(sorted_vals_e, sorted_vals_with_std_e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
