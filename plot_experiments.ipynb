{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading from CSV stats file to which run_experiments.py wrote. For this cell, you only need to change\n",
    "# the first 4 lines of code when carrying out experiments with a different configuration for the meta-features\n",
    "# and number of seeds. Instructions are there in the comments of these 4 lines. For other cells, instructions at their beginnings.\n",
    "###TODO Remove these extra dir names\n",
    "dir_name = '/home/anon/git/-MDP-Playground'\n",
    "dir_name = '/home/rajanr/custom-gym-env/backups/already_in_the_zip_backups_I_think'\n",
    "# dir_name = '/home/rajanr/git/custom-gym-env/backups'\n",
    "# dir_name = '/home/rajanr/Downloads/toy_rl_icml_new_data_plots/data' #'\n",
    "# dir_name = '/home/rajanr/custom-gym-env'\n",
    "stats_file = dir_name + '/' + '116' #Name of file to which benchmark stats were written\n",
    "num_values_per_hyperparam = (1, 1, 1, 5, 5, 10, 1, 3) # Dimension -3 must be set to the number of seeds,\n",
    "# Dimension -4 must be set to the size of the grid for meta-feature number 2 that was varied\n",
    "# (in this case 4 for sequence lengths), Dimension -5 must be set to the size of the grid for meta-feature\n",
    "# number 1 that was varied (in this case 5 for delays).\n",
    "\n",
    "import numpy as np\n",
    "datasets_info = np.loadtxt(stats_file + '.csv', dtype=object)\n",
    "# print(datasets_info[0])\n",
    "# print(datasets_info)\n",
    "# print(type(datasets_info))\n",
    "# print(datasets_info.shape)\n",
    "\n",
    "col_vals = np.array(datasets_info[:, 2:], dtype=float) # ignores 1st column - algo. name\n",
    "# print(col_vals)\n",
    "#hack\n",
    "final_rows_for_a_config = []\n",
    "\n",
    "previous_i = 0\n",
    "list_of_learning_curves = []\n",
    "cols_to_take = 8\n",
    "for i in range(col_vals.shape[0] - 1):\n",
    "\n",
    "    if col_vals[i, -3] > col_vals[i + 1, -3]: #hack: 3rd last column is no. of timesteps for the current run\n",
    "#         print(col_vals[i, 6])\n",
    "        list_of_learning_curves.append(col_vals[previous_i:i+1, -cols_to_take:])\n",
    "        previous_i = i + 1\n",
    "        final_rows_for_a_config.append(i)\n",
    "# print(\"i, previous_i:\", i, previous_i)\n",
    "final_rows_for_a_config.append(i + 1) # Always append the last row!\n",
    "list_of_learning_curves.append(col_vals[previous_i:i + 2, -cols_to_take:])\n",
    "\n",
    "# print(\"final_rows_for_a_config\", final_rows_for_a_config)\n",
    "# print(\"len(final_rows_for_a_config), len(list_of_learning_curves)\",\n",
    "#         len(final_rows_for_a_config), len(list_of_learning_curves))\n",
    "# print(list_of_learning_curves[0])\n",
    "# print(list_of_learning_curves[1])\n",
    "# print(list_of_learning_curves[-1])\n",
    "total_in_lcs = 0\n",
    "for i in range(len(list_of_learning_curves)):\n",
    "#     print(list_of_learning_curves[i].shape)\n",
    "    total_in_lcs += list_of_learning_curves[i].shape[0]\n",
    "# print(\"total_in_lcs\", total_in_lcs)\n",
    "final_vals = col_vals[final_rows_for_a_config]\n",
    "# print(\"final_vals.shape\", final_vals.shape)\n",
    "metrics_ = final_vals[:, -3:] # last vals are timesteps_total, episode_reward_mean, episode_len_mean\n",
    "metrics_reshaped = np.reshape(metrics_, num_values_per_hyperparam)\n",
    "# print(\"metrics_reshaped.shape\", metrics_reshaped.shape)\n",
    "to_plot_ = np.squeeze(metrics_reshaped[:, :, :, 0, 0, :, :, 1])\n",
    "# print(to_plot_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and loading for evaluation data written to CSV file!\n",
    "stats_file_eval = stats_file + '_eval.csv'\n",
    "eval_info = np.loadtxt(stats_file_eval, dtype=float)\n",
    "# print(eval_info, eval_info.shape)\n",
    "\n",
    "i = 0\n",
    "hack_indices = []\n",
    "for line in open(stats_file_eval):\n",
    "    \n",
    "    line=line.strip()\n",
    "#    print(line)\n",
    "    if line.startswith(\"#HACK\"):\n",
    "#         print(line, i)\n",
    "        hack_indices.append(i - len(hack_indices)) # appends index of last eval in this training_iteration\n",
    "    i += 1\n",
    "    \n",
    "# print(len(hack_indices), hack_indices)\n",
    "hack_indices_10 = np.array(hack_indices) - 10\n",
    "# print(hack_indices_10.shape, hack_indices_10)\n",
    "# print(np.array(hack_indices[1:]) - np.array(hack_indices[:-1]))\n",
    "# print(\"Min:\", min(np.array(hack_indices[1:]) - np.array(hack_indices[:-1]))) # Some problem with Ray? Sometimes no. of eval episodes is less than 10.\n",
    "final_10_evals = []\n",
    "for i in range(len(hack_indices)):\n",
    "    final_10_evals.append(eval_info[hack_indices_10[i]:hack_indices[i]])\n",
    "#     print(final_10_evals[-1])\n",
    "\n",
    "final_10_evals = np.array(final_10_evals) # has 2 columns: reward_this_episode and length_this_episode\n",
    "# print(final_10_evals.shape, final_10_evals)\n",
    "\n",
    "\n",
    "# final_vals = fin[final_rows_for_a_config]\n",
    "# print('final_rows_for_a_config', final_rows_for_a_config)\n",
    "# print(\"len(final_10_evals)\", final_10_evals.shape, type(final_10_evals))\n",
    "mean_data_eval = np.mean(final_10_evals, axis=1) # this is mean over last 10 eval episodes\n",
    "# print(mean_data_eval.shape, len(final_rows_for_a_config))\n",
    "final_eval_metrics_ = mean_data_eval[final_rows_for_a_config, -2:]\n",
    "# print(final_eval_metrics_.shape)\n",
    "num_values_per_hyperparam = list(num_values_per_hyperparam)\n",
    "num_values_per_hyperparam[-1] = 2 #hack to change number of recorded metrics from 3 for training to 2 for eval\n",
    "final_eval_metrics_reshaped = np.reshape(final_eval_metrics_, num_values_per_hyperparam)\n",
    "# print(\"final_eval_metrics_reshaped.shape\", final_eval_metrics_reshaped.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots across 10 runs: Training: with std dev across the runs\n",
    "# Change the labels and ticks below as per your experiment.\n",
    "import matplotlib.pyplot as plt\n",
    "y_axis_label = 'Delay'\n",
    "x_axis_label = 'Sequence length'\n",
    "y_tick_labels_ = [0, 0, 1, 2, 4, 8]\n",
    "x_tick_labels_ = [0, 1, 2, 3, 4]\n",
    "\n",
    "y_axis_label = 'Transition noise'\n",
    "x_axis_label = 'Reward noise'\n",
    "y_tick_labels_ = [0, 0, 0.01, 0.02, 0.10, 0.25, 0.5]\n",
    "x_tick_labels_ = [0, 0, 1, 5, 10, 25, 100]\n",
    "\n",
    "# y_axis_label = 'Delay'\n",
    "# x_axis_label = 'Sequence Length'\n",
    "# y_tick_labels_ = [\"\", \"0\"]\n",
    "# x_tick_labels_ = [\"\", 2, \"\", 3, \" \", 4]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Reward Density'\n",
    "# y_tick_labels_ = [\"\", \"\"]\n",
    "# x_tick_labels_ = [\"\", 0.25, \"\", 0.5, \" \", 0.75]\n",
    "# # x_tick_labels_ = [0, 0.25, 0.5, 0.75] # only for poster, hacky way to get ticks!\n",
    "\n",
    "# y_axis_label = 'n_step'\n",
    "# x_axis_label = 'n_atoms'\n",
    "# y_tick_labels_ = [\"\", 1,\"\", 2,\"\", 4,\"\", 8]\n",
    "# x_tick_labels_ = [0, 5, 10, 20]\n",
    "\n",
    "# y_axis_label = 'prioritized replay alpha'\n",
    "# x_axis_label = 'prioritized replay beta'\n",
    "# y_tick_labels_ = [\"\", 0.25, \"\", 0.5, \"\", 0.75, \"\", 1.0]\n",
    "# x_tick_labels_ = [0, 0.4, 0.7, 1.0]\n",
    "\n",
    "# y_axis_label = 'NN num layers'\n",
    "# x_axis_label = 'NN layer widths'\n",
    "# y_tick_labels_ = [\"\", 1, \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [0, 8, 32, 128]\n",
    "# x_tick_labels_ = [0, 128, 256, 512]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'NN neuron activation'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [\"\", \"tanh\", \"\", \"relu\", \"\", \"sigmoid\"]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Learning rate'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [\"\", \"1e-2\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\", \"sigmoid\"]\n",
    "\n",
    "# y_axis_label = 'DQN learning starts'\n",
    "# x_axis_label = 'DQN target net update freq.'\n",
    "# y_tick_labels_ = [\"\", 500, \"\", 1000, \"\", 2000, \"\", 4000]\n",
    "# y_tick_labels_ = [\"\", 1000, \"\", 2000, \"\", 4000]\n",
    "# # y_tick_labels_ = [\"\", 500, \"1000\", 2000, \"4000\", 8000, \"\", 4000]\n",
    "# x_tick_labels_ = [0, 8, 80, 800]\n",
    "# x_tick_labels_ = [0, 80, \"\", 800, \"\", 8000]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Double DQN'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", \"\",]\n",
    "# x_tick_labels_ = [0, \"False\", \"True\"]\n",
    "\n",
    "\n",
    "# y_axis_label = 'Learning rate'\n",
    "# x_axis_label = 'Adam epsilon'\n",
    "# y_tick_labels_ = [\"\", \"1e-2\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\"]\n",
    "# x_tick_labels_ = [\"\", \"1e-1\", \"1e-4\", \"1e-7\", \"1e-10\", \"\"]\n",
    "# x_tick_labels_ = [\"\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\", \"\"]\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 12}) # default 12, for poster: 30\n",
    "\n",
    "mean_data_ = np.mean(metrics_reshaped[:, 0, 0, :, :, :, :, 1], axis=-2)\n",
    "to_plot_ = np.squeeze(mean_data_)\n",
    "# print(np.squeeze(metrics_reshaped[:, 0, 0, :, :, :, :, 0]),\n",
    "#       metrics_reshaped[:, :, :, :, :, :, :, :].shape)\n",
    "# print(to_plot_, to_plot_.shape)\n",
    "plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_))\n",
    "plt.gca().set_xticklabels(x_tick_labels_)\n",
    "plt.gca().set_yticklabels(y_tick_labels_)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.get_yaxis().labelpad = 15 # default 15, for poster: 25\n",
    "cbar.set_label('Reward', rotation=270)\n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.savefig(stats_file.split('/')[-1] + '_train_final_reward_mean_heat_map.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "std_dev_ = np.std(metrics_reshaped[:, 0, 0, :, :, :, :, 1], axis=-2)\n",
    "to_plot_ = np.squeeze(std_dev_)\n",
    "# print(to_plot_, to_plot_.shape)\n",
    "plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_)) # 60 for DQN, 100 for A3C\n",
    "plt.gca().set_xticklabels(x_tick_labels_)\n",
    "plt.gca().set_yticklabels(y_tick_labels_)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.get_yaxis().labelpad = 15 # default 15, for poster: 30\n",
    "cbar.set_label('Reward Std Dev.', rotation=270)\n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "# plt.tight_layout()\n",
    "plt.savefig(stats_file.split('/')[-1] + '_train_final_reward_std_heat_map.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(stats_file.split('/')[-1] + '_train_heat_map.png')#, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but for eval metrics; Plots across 10 runs: with std dev across the runs\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "mean_data_ = np.mean(final_eval_metrics_reshaped[:, 0, 0, :, :, :, :, 0], axis=-2)\n",
    "to_plot_ = np.squeeze(mean_data_)\n",
    "# print(np.squeeze(final_eval_metrics_reshaped[:, 0, 0, :, :, :, :, 0]),\n",
    "#       final_eval_metrics_reshaped[:, :, :, :, :, :, :, :].shape)\n",
    "# import matplotlib.pyplot as plt\n",
    "plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_))\n",
    "plt.gca().set_xticklabels(x_tick_labels_)\n",
    "plt.gca().set_yticklabels(y_tick_labels_)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "cbar.set_label('Reward', rotation=270)\n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.savefig(stats_file.split('/')[-1] + '_eval_final_reward_mean_heat_map.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "std_dev_ = np.std(final_eval_metrics_reshaped[:, 0, 0, :, :, :, :, 0], axis=-2)\n",
    "to_plot_ = np.squeeze(std_dev_)\n",
    "# print(to_plot_, to_plot_.shape)\n",
    "plt.imshow(np.atleast_2d(to_plot_), cmap='Purples', interpolation='none', vmin=0, vmax=np.max(to_plot_))\n",
    "plt.gca().set_xticklabels(x_tick_labels_)\n",
    "plt.gca().set_yticklabels(y_tick_labels_)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "cbar.set_label('Reward Std Dev.', rotation=270)\n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.savefig(stats_file.split('/')[-1] + '_eval_final_reward_std_heat_map.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for train metrics: learning curves; with subplot\n",
    "# Comment out unneeded labels in code lines 41-44 in this cell\n",
    "nrows_ = num_values_per_hyperparam[-5]\n",
    "ncols_ = num_values_per_hyperparam[-4]\n",
    "nseeds_ = num_values_per_hyperparam[-3]\n",
    "# print(ax, type(ax), type(ax[0]))\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25}) # 25 for 36x21 fig, 16 for 24x14 fig.\n",
    "# 36x21 for better resolution but about 900kb file size, 24x14 for okay resolution and 550kb file size\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=(7 * ncols_, 5 * nrows_))\n",
    "ax = np.atleast_2d(ax)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = col_vals[0:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False)#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "#         ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "        ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()\n",
    "# plt.suptitle(\"Training Learning Curves\")\n",
    "plt.show()\n",
    "fig.savefig(stats_file.split('/')[-1] + '_train_learning_curves.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb; dpi doesn't matter for this\n",
    "# fig.savefig(stats_file.split('/')[-1] + '_train_learning_curves.png', dpi=30) # Generates okay quality rasterized PNG 250kb for 36x21 fig above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for eval metrics: learning curves; with subplots\n",
    "# Comment out unneeded labels in code lines 37-40 in this cell\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=((7 * ncols_, 5 * nrows_))) # (36,21) plots for paper\n",
    "ax = np.atleast_2d(ax)\n",
    "# print(mean_data_eval.shape, col_vals.shape)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval[0:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = mean_data_eval[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     plt.plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "#         ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "        ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()#pad=1, w_pad=1, h_pad=2.0)\n",
    "plt.show()\n",
    "fig.savefig(stats_file.split('/')[-1] + '_eval_learning_curves.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb\n",
    "# fig.savefig(stats_file.split('/')[-1] + '_eval_learning_curves.png', dpi=30) # Generates okay quality rasterized PNG 250kb for 36x21 fig above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D: Plots showing reward after 20k timesteps when varying a single meta-feature\n",
    "# Plots across 10 runs: Training: with std dev across the runs\n",
    "# Change the labels and ticks below as per your experiment.\n",
    "import matplotlib.pyplot as plt\n",
    "y_axis_label = 'Reward'\n",
    "\n",
    "x_axis_label = 'Delay'\n",
    "x_axis_label2 = 'Sequence length'\n",
    "x_tick_labels_ = ['0', '1', '2', '4', '8']\n",
    "x_tick_labels_2 = ['1', '2', '3', '4']\n",
    "\n",
    "x_axis_label = 'Transition noise'\n",
    "x_axis_label2 = 'Reward noise'\n",
    "x_tick_labels_ = ['0', '0.01', '0.02', '0.10', '0.25']\n",
    "x_tick_labels_2 = ['0', '1', '5', '10', '25']\n",
    "\n",
    "# x_axis_label = 'Sequence Length'\n",
    "# x_tick_labels_ = ['2', '3', '4']\n",
    "\n",
    "# x_axis_label = 'Reward Density'\n",
    "# x_tick_labels_ = ['0.25', '0.5', '0.75']\n",
    "# # x_tick_labels_ = [0, 0.25, 0.5, 0.75] # only for poster, hacky way to get ticks!\n",
    "\n",
    "# y_axis_label = 'n_step'\n",
    "# x_axis_label = 'n_atoms'\n",
    "# y_tick_labels_ = [\"\", 1,\"\", 2,\"\", 4,\"\", 8]\n",
    "# x_tick_labels_ = [0, 5, 10, 20]\n",
    "\n",
    "# y_axis_label = 'prioritized replay alpha'\n",
    "# x_axis_label = 'prioritized replay beta'\n",
    "# y_tick_labels_ = [\"\", 0.25, \"\", 0.5, \"\", 0.75, \"\", 1.0]\n",
    "# x_tick_labels_ = [0, 0.4, 0.7, 1.0]\n",
    "\n",
    "# y_axis_label = 'NN num layers'\n",
    "# x_axis_label = 'NN layer widths'\n",
    "# y_tick_labels_ = [\"\", 1, \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [0, 8, 32, 128]\n",
    "# x_tick_labels_ = [0, 128, 256, 512]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'NN neuron activation'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [\"\", \"tanh\", \"\", \"relu\", \"\", \"sigmoid\"]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Learning rate'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", 2, \"\", 3, \"\", 4]\n",
    "# x_tick_labels_ = [\"\", \"1e-2\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\", \"sigmoid\"]\n",
    "\n",
    "# y_axis_label = 'DQN learning starts'\n",
    "# x_axis_label = 'DQN target net update freq.'\n",
    "# y_tick_labels_ = [\"\", 500, \"\", 1000, \"\", 2000, \"\", 4000]\n",
    "# y_tick_labels_ = [\"\", 1000, \"\", 2000, \"\", 4000]\n",
    "# # y_tick_labels_ = [\"\", 500, \"1000\", 2000, \"4000\", 8000, \"\", 4000]\n",
    "# x_tick_labels_ = [0, 8, 80, 800]\n",
    "# x_tick_labels_ = [0, 80, \"\", 800, \"\", 8000]\n",
    "\n",
    "# y_axis_label = ''\n",
    "# x_axis_label = 'Double DQN'\n",
    "# y_tick_labels_ = [\"\", \"\", \"\", \"\",]\n",
    "# x_tick_labels_ = [0, \"False\", \"True\"]\n",
    "\n",
    "\n",
    "# y_axis_label = 'Learning rate'\n",
    "# x_axis_label = 'Adam epsilon'\n",
    "# y_tick_labels_ = [\"\", \"1e-2\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\"]\n",
    "# x_tick_labels_ = [\"\", \"1e-1\", \"1e-4\", \"1e-7\", \"1e-10\", \"\"]\n",
    "# x_tick_labels_ = [\"\", \"1e-3\", \"1e-4\", \"1e-5\", \"1e-6\", \"\"]\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 18}) # default 12, for poster: 30\n",
    "\n",
    "mean_data_ = np.mean(metrics_reshaped[:, 0, 0, :, :, :, :, 1], axis=-2)\n",
    "to_plot_ = np.squeeze(mean_data_)\n",
    "std_dev_ = np.std(metrics_reshaped[:, 0, 0, :, :, :, :, 1], axis=-2)\n",
    "to_plot_std_ = np.squeeze(std_dev_)\n",
    "# print(to_plot_[:, 0])\n",
    "# plt.errorbar(['0', '1', '2', '4', '8'], to_plot_[:, 0], yerr=to_plot_std_[:, 0], fmt='b_-', ls='none', capsize=4, elinewidth=0.005)#, barsabove=True)\n",
    "plt.figure(figsize=(5, 1.5))\n",
    "if len(to_plot_.shape) == 2: # Case when 2 meta-features were varied\n",
    "    plt.bar(x_tick_labels_, to_plot_[:, 0], yerr=to_plot_std_[:, 0])\n",
    "else:\n",
    "    plt.bar(x_tick_labels_, to_plot_, yerr=to_plot_std_)    \n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.savefig(stats_file.split('/')[-1] + '_train_final_reward_' + x_axis_label.replace(' ','') + '_1d.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "if len(to_plot_.shape) == 2: # Case when 2 meta-features were varied\n",
    "    plt.figure(figsize=(5, 1.5))\n",
    "    plt.bar(x_tick_labels_2, to_plot_[0, :], yerr=to_plot_std_[0, :])\n",
    "    # plt.tight_layout()\n",
    "    plt.xlabel(x_axis_label2)\n",
    "    plt.ylabel(y_axis_label)\n",
    "    plt.savefig(stats_file.split('/')[-1] + '_train_final_reward_' + x_axis_label2.replace(' ','') + '_1d.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "###TODO save PDFs instead of PNGs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above but for eval: 1-D: Plots showing reward after 20k timesteps when varying a single meta-feature\n",
    "# Plots across 10 runs: Eval.: with std dev across the runs\n",
    "# Change the labels and ticks below as per your experiment.\n",
    "\n",
    "plt.rcParams.update({'font.size': 18}) # default 18, for poster: 30\n",
    "\n",
    "mean_data_ = np.mean(final_eval_metrics_reshaped[:, 0, 0, :, :, :, :, 0], axis=-2)\n",
    "to_plot_ = np.squeeze(mean_data_)\n",
    "std_dev_ = np.std(final_eval_metrics_reshaped[:, 0, 0, :, :, :, :, 0], axis=-2)\n",
    "to_plot_std_ = np.squeeze(std_dev_)\n",
    "# print(to_plot_[:, 0], to_plot_std_[:, 0])\n",
    "# plt.errorbar(['0', '1', '2', '4', '8'], to_plot_[:, 0], yerr=to_plot_std_[:, 0], fmt='b_-', ls='none', capsize=4, elinewidth=0.005)#, barsabove=True)\n",
    "# plt.figure(figsize=(9*4, 7*3))\n",
    "plt.figure(figsize=(5, 1.5))\n",
    "if len(to_plot_.shape) == 2: # Case when 2 meta-features were varied\n",
    "    plt.bar(x_tick_labels_, to_plot_[:, 0], yerr=to_plot_std_[:, 0])\n",
    "else:\n",
    "    plt.bar(x_tick_labels_, to_plot_, yerr=to_plot_std_)\n",
    "plt.xlabel(x_axis_label)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.savefig(stats_file.split('/')[-1] + '_eval_final_reward_' + x_axis_label.replace(' ','') + '_1d.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if len(to_plot_.shape) == 2: # Case when 2 meta-features were varied\n",
    "    # print(to_plot_[0, :], to_plot_std_[0, :])\n",
    "    plt.figure(figsize=(5, 1.5))\n",
    "    plt.bar(x_tick_labels_2, to_plot_[0, :], yerr=to_plot_std_[0, :])\n",
    "    # plt.tight_layout()\n",
    "    plt.xlabel(x_axis_label2)\n",
    "    plt.ylabel(y_axis_label)\n",
    "    plt.savefig(stats_file.split('/')[-1] + '_eval_final_reward_' + x_axis_label2.replace(' ','') + '_1d.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default plots for specific cases plotted in the paper\n",
    "col_vals_dqn = col_vals\n",
    "final_rows_for_a_config_dqn = final_rows_for_a_config\n",
    "mean_data_eval_dqn = mean_data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_vals_a3c = col_vals\n",
    "final_rows_for_a_config_a3c = final_rows_for_a_config\n",
    "mean_data_eval_a3c = mean_data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default plots for specific cases plotted in the paper\n",
    "# Plot for train metrics: learning curves; with subplot\n",
    "# Comment out unneeded labels in code lines 41-44 in this cell\n",
    "nrows_ = num_values_per_hyperparam[-5]\n",
    "ncols_ = num_values_per_hyperparam[-4]\n",
    "nseeds_ = num_values_per_hyperparam[-3]\n",
    "# print(ax, type(ax), type(ax[0]))\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25}) # 25 for 36x21 fig, 16 for 24x14 fig.\n",
    "# 36x21 for better resolution but about 900kb file size, 24x14 for okay resolution and 550kb file size\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=(7 * ncols_, 5 * nrows_))\n",
    "ax = np.atleast_2d(ax)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config_dqn)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = col_vals_dqn[0:final_rows_for_a_config_dqn[i]+1,-2]\n",
    "        to_plot_x = col_vals_dqn[0:final_rows_for_a_config_dqn[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = col_vals_dqn[final_rows_for_a_config_dqn[i-1]+1:final_rows_for_a_config_dqn[i]+1,-2]\n",
    "        to_plot_x = col_vals_dqn[final_rows_for_a_config_dqn[i-1]+1:final_rows_for_a_config_dqn[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False, c='b')#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    ax[i_index][j_index].set_xscale('log')\n",
    "\n",
    "\n",
    "for i in range(len(final_rows_for_a_config_a3c)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = col_vals_a3c[0:final_rows_for_a_config_a3c[i]+1,-2]\n",
    "        to_plot_x = col_vals_a3c[0:final_rows_for_a_config_a3c[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = col_vals_a3c[final_rows_for_a_config_a3c[i-1]+1:final_rows_for_a_config_a3c[i]+1,-2]\n",
    "        to_plot_x = col_vals_a3c[final_rows_for_a_config_a3c[i-1]+1:final_rows_for_a_config_a3c[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False, c='g')#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "        ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()\n",
    "# plt.suptitle(\"Training Learning Curves\")\n",
    "plt.show()\n",
    "fig.savefig(stats_file.split('/')[-1] + '_dqn_a3c_train_learning_curves_combo_log_scale.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb; dpi doesn't matter for this\n",
    "# fig.savefig(stats_file.split('/')[-1] + '_train_learning_curves.png', dpi=30) # Generates okay quality rasterized PNG 250kb for 36x21 fig above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Non-default plots for specific cases plotted in the paper\n",
    "# Plot for train metrics: learning curves; with subplot\n",
    "# Comment out unneeded labels in code lines 41-44 in this cell\n",
    "\n",
    "# vanilla environment single plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "for i in range(len(final_rows_for_a_config_dqn)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "#     print(i, i_index, j_index)\n",
    "    if j_index > 0:\n",
    "        break\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval_dqn[0:final_rows_for_a_config_dqn[i]+1,-2]\n",
    "        to_plot_x = col_vals_dqn[0:final_rows_for_a_config_dqn[i]+1,-3]\n",
    "        plt.plot(to_plot_x, to_plot_, rasterized=False, c='b', alpha=0.25, label='DQN')#, label=\"Seq len\" + \n",
    "    else:\n",
    "        to_plot_ = mean_data_eval_dqn[final_rows_for_a_config_dqn[i-1]+1:final_rows_for_a_config_dqn[i]+1,-2]\n",
    "        to_plot_x = col_vals_dqn[final_rows_for_a_config_dqn[i-1]+1:final_rows_for_a_config_dqn[i]+1,-3]\n",
    "        plt.plot(to_plot_x, to_plot_, rasterized=False, c='b', alpha=0.25)#, label=\"Seq len\" + \n",
    "\n",
    "# plt.show()\n",
    "\n",
    "for i in range(len(final_rows_for_a_config_a3c)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if j_index > 0:\n",
    "        break\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval_a3c[0:final_rows_for_a_config_a3c[i]+1,-2]\n",
    "        to_plot_x = col_vals_a3c[0:final_rows_for_a_config_a3c[i]+1,-3]\n",
    "        plt.plot(to_plot_x, to_plot_, rasterized=False, c='g', alpha=0.25, label='A3C')#, label=\"Seq len\" + \n",
    "    else:\n",
    "        to_plot_ = mean_data_eval_a3c[final_rows_for_a_config_a3c[i-1]+1:final_rows_for_a_config_a3c[i]+1,-2]\n",
    "        to_plot_x = col_vals_a3c[final_rows_for_a_config_a3c[i-1]+1:final_rows_for_a_config_a3c[i]+1,-3]\n",
    "        plt.plot(to_plot_x, to_plot_, rasterized=False, c='g', alpha=0.25)#, label=\"Seq len\" + \n",
    "plt.xscale('log')\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Train timesteps')\n",
    "plt.legend(loc='upper left', prop={'size': 16})\n",
    "plt.savefig(stats_file.split('/')[-1] + '_dqn_a3c_eval_learning_curves_combo_log_scale_vanilla_env.pdf', dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# grid part\n",
    "nrows_ = num_values_per_hyperparam[-5]\n",
    "ncols_ = num_values_per_hyperparam[-4]\n",
    "nseeds_ = num_values_per_hyperparam[-3]\n",
    "# print(ax, type(ax), type(ax[0]))\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25}) # 25 for 36x21 fig, 16 for 24x14 fig.\n",
    "# 36x21 for better resolution but about 900kb file size, 24x14 for okay resolution and 550kb file size\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=(7 * ncols_, 5 * nrows_))\n",
    "ax = np.atleast_2d(ax)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "\n",
    "\n",
    "for i in range(len(final_rows_for_a_config_dqn)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval_dqn[0:final_rows_for_a_config_dqn[i]+1,-2]\n",
    "        to_plot_x = col_vals_dqn[0:final_rows_for_a_config_dqn[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = mean_data_eval_dqn[final_rows_for_a_config_dqn[i-1]+1:final_rows_for_a_config_dqn[i]+1,-2]\n",
    "        to_plot_x = col_vals_dqn[final_rows_for_a_config_dqn[i-1]+1:final_rows_for_a_config_dqn[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False, c='b')#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    ax[i_index][j_index].set_xscale('log')\n",
    "\n",
    "for i in range(len(final_rows_for_a_config_a3c)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval_a3c[0:final_rows_for_a_config_a3c[i]+1,-2]\n",
    "        to_plot_x = col_vals_a3c[0:final_rows_for_a_config_a3c[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = mean_data_eval_a3c[final_rows_for_a_config_a3c[i-1]+1:final_rows_for_a_config_a3c[i]+1,-2]\n",
    "        to_plot_x = col_vals_a3c[final_rows_for_a_config_a3c[i-1]+1:final_rows_for_a_config_a3c[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False, c='g')#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "        ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()\n",
    "# plt.suptitle(\"Training Learning Curves\")\n",
    "plt.show()\n",
    "fig.savefig(stats_file.split('/')[-1] + '_dqn_a3c_eval_learning_curves_combo_log_scale.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb; dpi doesn't matter for this\n",
    "# fig.savefig(stats_file.split('/')[-1] + '_train_learning_curves.png', dpi=30) # Generates okay quality rasterized PNG 250kb for 36x21 fig above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default plots for specific cases plotted in the paper\n",
    "# Plot for train metrics: learning curves; with subplot\n",
    "# Comment out unneeded labels in code lines 41-44 in this cell\n",
    "nrows_ = num_values_per_hyperparam[-5]\n",
    "ncols_ = num_values_per_hyperparam[-4]\n",
    "nseeds_ = num_values_per_hyperparam[-3]\n",
    "# print(ax, type(ax), type(ax[0]))\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25}) # 25 for 36x21 fig, 16 for 24x14 fig.\n",
    "# 36x21 for better resolution but about 900kb file size, 24x14 for okay resolution and 550kb file size\n",
    "fig, ax = plt.subplots(nrows=1, ncols=ncols_, figsize=(7 * ncols_, 1 * nrows_))\n",
    "ax = np.atleast_2d(ax)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    if i_index > 0:\n",
    "        break\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = col_vals[0:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-2]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     print(i//50, (i//10) % 5)\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_, rasterized=False)#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "        ax[i_index][j_index].set_title('Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()\n",
    "# plt.suptitle(\"Training Learning Curves\")\n",
    "plt.show()\n",
    "fig.savefig(stats_file.split('/')[-1] + '_1d_train_learning_curves.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb; dpi doesn't matter for this\n",
    "# fig.savefig(stats_file.split('/')[-1] + '_train_learning_curves.png', dpi=30) # Generates okay quality rasterized PNG 250kb for 36x21 fig above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-default plots for specific cases plotted in the paper\n",
    "# Plot for eval metrics: learning curves; with subplots\n",
    "# Comment out unneeded labels in code lines 37-40 in this cell\n",
    "color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "# print(\"color_cycle\", color_cycle)\n",
    "seq_lens = [2, 3, 4]\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "#fig = plt.figure(figsize=(9*4, 7*3)) #\n",
    "fig, ax = plt.subplots(nrows=nrows_, ncols=ncols_, figsize=((7 * ncols_, 5 * nrows_))) # (36,21) plots for paper\n",
    "ax = np.atleast_2d(ax)\n",
    "# print(mean_data_eval.shape, col_vals.shape)\n",
    "# metrics_reshaped_squeezed = np.squeeze(metrics_reshaped)\n",
    "# print(np.squeeze(metrics_reshaped).shape)\n",
    "delays = [0] + [2**i for i in range(4)]\n",
    "sequence_lengths = [1, 2, 3, 4]#i for i in range(1,4)]\n",
    "transition_noises = [0, 0.01, 0.02, 0.10, 0.25]\n",
    "reward_noises = [0, 1, 5, 10, 25] # Std dev. of normal dist. #, lambda a: a.normal(0, 0.1), lambda a: a.normal(0, 0.25), lambda a: a.normal(0, 0.5),]\n",
    "# sequence_lengths = [2, 3, 4]#i for i in range(1,4)]\n",
    "reward_densities = [0.25, 0.50, 0.75]\n",
    "for i in range(len(final_rows_for_a_config)):\n",
    "    i_index = i//(nseeds_ * ncols_) # = num_seeds * shape of more frequently changing hyperparam\n",
    "    j_index = (i//nseeds_) % ncols_ #\n",
    "    if i == 0:\n",
    "        to_plot_ = mean_data_eval[0:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[0:final_rows_for_a_config[i]+1,-3]\n",
    "    else:\n",
    "        to_plot_ = mean_data_eval[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,:]\n",
    "        to_plot_x = col_vals[final_rows_for_a_config[i-1]+1:final_rows_for_a_config[i]+1,-3]\n",
    "#     if i % 10 == 0:\n",
    "#         fig = plt.figure(figsize=(12, 7))\n",
    "#     plt.plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    ax[i_index][j_index].plot(to_plot_x, to_plot_[:, 0])#, label=\"Seq len\" + str(seq_lens[i//10]))\n",
    "    if i % nseeds_ == nseeds_ - 1: # 10 is num. of seeds\n",
    "#         pass\n",
    "#         print(\"Plot no.\", i//10)\n",
    "        ax[i_index][j_index].set_xlabel(\"Train Timesteps\")\n",
    "        ax[i_index][j_index].set_ylabel(\"Reward\")\n",
    "#         ax[i_index][j_index].set_title('Delay ' + str(delays[i_index]) + ', Sequence Length ' + str(sequence_lengths[j_index]))\n",
    "#         ax[i_index][j_index].set_title('P Noise ' + str(transition_noises[i_index]) + ', R Noise ' + str(reward_noises[j_index]))\n",
    "#         ax[i_index][j_index].set_title('Sequence Length ' + str(seq_lens[j_index]))\n",
    "        ax[i_index][j_index].set_title('Reward Density ' + str(reward_densities[j_index]))\n",
    "#         plt.legend(loc='upper left', prop={'size': 26})\n",
    "fig.tight_layout()#pad=1, w_pad=1, h_pad=2.0)\n",
    "plt.show()\n",
    "fig.savefig(stats_file.split('/')[-1] + '_eval_learning_curves.pdf', dpi=300, bbox_inches=\"tight\") # Generates high quality vector graphic PDF 125kb\n",
    "# fig.savefig(stats_file.split('/')[-1] + '_eval_learning_curves.png', dpi=30) # Generates okay quality rasterized PNG 250kb for 36x21 fig above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
